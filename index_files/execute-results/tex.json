{
  "hash": "335b8431fbb04ed42213b681cb436493",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian Logistic Regression for Predicting Diabetes Risk Using NHANES 2013–2014 Data\"\nsubtitle: \"A Capstone Project on Bayesian Applications in Epidemiologic Modeling\"\nauthor:\n  - \"Namita Mishra\"\n  - \"Autumn Wilcox\"\nadvisor: \"Dr. Ashraf Cohen\"\ndate: '2025-11-10'\ncourse: Capstone Projects in Data Science\n\nexecute:\n  echo: false       \n  warning: false\n  message: false\n  cache: false\n  \nformat:\n  html:\n    code-fold: true \n  pdf: \n    toc: true\n    number-sections: true\n    geometry: margin=1in\n\nbibliography: references.bib\nreference-section-title: \"References\"\nlink-citations: true\nself-contained: true\n\neditor:\n  markdown:\n    wrap: 72\n---\n\n\n\nSlides: [slides.html](slides.html){target=\"_blank\"} (Edit `slides.qmd`.)\n\n# Introduction\n\nDiabetes mellitus (DM) remains a major public health challenge, and\nidentifying key risk factors—such as obesity, age, sex, and\nrace/ethnicity—is essential for prevention and targeted intervention.\nLogistic regression is widely used to estimate associations between such\nfactors and binary outcomes like diabetes diagnosis. However, classical\nmaximum likelihood estimation (MLE) can produce unstable estimates in\nthe presence of missing data, quasi-separation, or small samples.\nBayesian logistic regression offers a robust alternative by integrating\nprior information, regularizing estimates, and quantifying uncertainty\nmore transparently than frequentist approaches.\n\nBayesian hierarchical models, implemented via Markov Chain Monte Carlo\n(MCMC), have been successfully applied in predicting patient health\nstatus across diseases such as pneumonia, prostate cancer, and mental\ndisorders [@zeger2020]. By representing predictive uncertainty alongside\npoint estimates, Bayesian inference offers a practical advantage in\nepidemiologic modeling where decisions hinge on probabilistic\nthresholds. Beyond stability, Bayesian methods support model checking,\nvariable selection, and uncertainty quantification under missingness or\nimputation frameworks [@baldwin2017; @kruschke2017].\n\nRecent work has expanded Bayesian applications to disease diagnostics\nand health risk modeling. For instance, Bayesian approaches have been\nused to evaluate NHANES diagnostic data [@chatzimichail2023], to model\ncardiovascular and metabolic risk [@liu2013], and to integrate multiple\ndata modalities such as imaging and laboratory measures\n[@abdullah2022bdlhealth]. Moreover, multiple imputation combined with\nBayesian modeling generates robust estimates when data are missing at\nrandom (MAR) or not at random (MNAR) [@austin2021].\n\nThe broader Bayesian literature emphasizes the role of priors and model\nchecking. Weakly informative priors, such as $N(0, 2.5)$ for\ncoefficients, regularize estimation and reduce variance in small samples\n[@gelman2008; @vandeschoot2021]. Tutorials using R packages like `brms`\nand `blavaan` illustrate how MCMC enables posterior inference and\nempirical Bayes analysis [@klauenberg2015].\n\nBeyond standard generalized linear models, Bayesian nonparametric\nregression flexibly captures nonlinearity and zero inflation common in\nhealth data [@richardson2018bnr]. Bayesian Additive Regression Trees\n(BART) improve variable selection in mixed-type data [@luo2024bartvs],\nwhile state-space and dynamic Bayesian models incorporate time-varying\nbiomarkers for longitudinal prediction [@momeni2021covidbayes]. Bayesian\nmodel averaging (BMA) further addresses model uncertainty by weighting\nacross multiple specifications [@hoeting1999bma]. Together, these\napproaches demonstrate the versatility and growing importance of\nBayesian inference in clinical and epidemiologic modeling.\n\nThe objective of this project is to evaluate whether Bayesian inference\nprovides more stable and interpretable estimates of diabetes risk than\nfrequentist and imputation-based approaches, particularly when data\ncomplexity or separation challenges arise. Agreement across modeling\nframeworks supports the robustness of these associations and highlights\nthe interpretability and uncertainty quantification advantages offered\nby Bayesian analysis in population health modeling [@nchs2014].\n\n## Aims\n\nThe present study employs Bayesian logistic regression to predict\ndiabetes status and examine the relationships between diabetes and key\npredictors, including body mass index (BMI), age (≥20 years), sex, and\nrace. Using retrospective data from the 2013–2014 NHANES survey, the\nanalysis accounts for the study’s complex sampling design, which\ninvolves stratification, clustering, and the oversampling of specific\nsubpopulations rather than simple random sampling. The Bayesian\nframework is applied to address common analytical challenges such as\nmissing data, complete case bias, and data separation, thereby improving\nthe robustness and reliability of inference compared to traditional\nlogistic regression methods.\n\n# Method\n\n## Bayesian Logistic Regression\n\nThe Bayesian framework integrates prior knowledge with observed data to\ngenerate posterior distributions, allowing parameters to be interpreted\ndirectly in probabilistic terms.\n\nUnlike traditional frequentist approaches that yield single-point\nestimates and p-values, Bayesian methods represent parameters as random\nvariables with full probability distributions.\n\nThis provides greater flexibility, incorporates parameter uncertainty,\nand produces credible intervals that directly quantify the probability\nthat a parameter lies within a given range.\n\n## Model Structure\n\nBayesian logistic regression models the log-odds of a binary outcome as\na linear combination of predictors:\n\n$$\n\\text{logit}(P(Y = 1)) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_k X_k\n$$\n\nwhere\n\n-   $P(Y = 1)$ is the probability of the event of interest,\n-   $\\beta_0$ is the intercept (log-odds when all predictors are zero),\n    and\n-   $\\beta_j$ represents the effect of predictor $X_j$ on the log-odds\n    of the outcome, holding other predictors constant.\n\nIn the Bayesian framework, model parameters ($\\boldsymbol{\\beta}$) are\ntreated as random variables and assigned prior distributions that\nreflect existing knowledge or plausible ranges before observing the\ndata. After incorporating the observed evidence, the priors are updated\nthrough Bayes’ theorem [@deleeuw2012; @klauenberg2015]:\n\n$$\n\\text{Posterior} \\propto \\text{Likelihood} \\times \\text{Prior}\n$$\n\n-   **Likelihood:** represents the probability of the observed data\n    given the model parameters—it captures how well different parameter\n    values explain the data.\n-   **Prior:** expresses beliefs or existing information about the\n    parameters before observing the data.\n-   **Posterior:** combines both, representing the updated distribution\n    of parameter values after accounting for the data.\n\nThis formulation allows uncertainty to propagate naturally through the\nmodel, producing posterior distributions for each coefficient that can\nbe directly interpreted as probabilities.\n\n## Prior Specification\n\nWeakly informative priors were used to regularize estimation without\nimposing strong assumptions:\n\n-   **Regression Coefficients:** $N(0, 2.5)$, providing gentle\n    regularization while allowing substantial variation in plausible\n    effects [@gelman2008; @vandeschoot2021].\n-   **Intercept:** Student’s t-distribution prior, $t(3, 0, 10)$\n    [@vandeschoot2013; @vandeschoot2021], which has\n    -   3 degrees of freedom (heavy tails to allow occasional large\n        effects),\n    -   mean 0 (no bias toward positive or negative effects), and\n    -   scale 10 (broad range of possible values).\n\nSuch priors help stabilize estimation in the presence of\nmulticollinearity, limited sample size, or potential outliers.\n\n## Posterior Predictions\n\nPosterior distributions of regression coefficients were used to estimate\nthe probability of the outcome for given predictor values. This allows\nstatements such as: \\> Given the predictors, the probability of the\noutcome lies between X% and Y%.\n\nPosterior predictions account for two key sources of uncertainty:\n\n1.  **Parameter Uncertainty:** Variability in estimated model\n    coefficients.\n2.  **Predictive Uncertainty:** Variability in possible future outcomes\n    given those parameters.\n\nIn Bayesian analysis, all unknown quantities—coefficients, means,\nvariances, or probabilities—are treated as random variables described by\ntheir posterior distributions.\n\n## Model Evaluation and Diagnostics\n\nModel quality and convergence were assessed using standard Bayesian\ndiagnostics:\n\n-   **Posterior Sampling:** Conducted via Markov Chain Monte\n    Carlo (MCMC) using the No-U-Turn Sampler (NUTS), a variant of\n    Hamiltonian Monte Carlo (HMC) [@austin2021]. Four chains were run\n    with sufficient warm-up iterations to ensure convergence.\n-   **Convergence Metrics:** The potential scale reduction factor\n    ($\\hat{R}$) and effective sample size (ESS) were used to verify\n    stability and mixing across chains.\n-   **Autocorrelation Checks:** Ensured independence between successive\n    draws.\n-   **Posterior Predictive Checks (PPCs):** Compared simulated outcomes\n    to observed data to evaluate fit.\n-   **Bayesian** $R^2$: Quantified the proportion of variance explained\n    by predictors, incorporating posterior uncertainty.\n\n## Advantages of Bayesian Logistic Regression\n\n-   **Uncertainty Quantification:** Produces full posterior\n    distributions instead of single estimates.\n-   **Credible Intervals:** Provide the range within which a parameter\n    lies with a specified probability (e.g., 95%).\n-   **Flexible Priors:** Allow integration of expert knowledge or\n    findings from prior studies.\n-   **Probabilistic Predictions:** Posterior predictive distributions\n    yield direct probabilities for new or future observations.\n-   **Model Evaluation:** PPCs assess how well simulated outcomes\n    reproduce observed data.\n\n# Analysis and Results\n\n## Data Preparation\n\nThis study used publicly available 2013–2014 NHANES data published by\nthe CDC’s National Center for Health Statistics [@nchs2014]. Three\ncomponent files were utilized: `DEMO_H` (demographics), `BMX_H` (body\nmeasures), and `DIQ_H` (diabetes questionnaire). Each file was imported\nin `.XPT` format using the **`haven`** package in **R**, and merged\nusing the unique participant identifier `SEQN` to create a single adult\nanalytic dataset (age ≥ 20 years).\n\nAll variables were coerced to consistent numeric or factor types prior\nto merging to ensure atomic columns suitable for survey-weighted\nanalysis and modeling. The use of `SEQN` preserved respondent integrity\nacross datasets and ensured accurate record linkage. This preprocessing\nstep standardized variable formats and minimized inconsistencies between\nfiles.\n\nData wrangling, cleaning, and merging were performed in **R** using a\ncombination of base functions and tidyverse packages. Bayesian logistic\nregression modeling was later implemented using the **`brms`** interface\nto **Stan**, allowing probabilistic inference within a reproducible\nworkflow that accommodated the NHANES complex survey design and missing\ndata considerations.\n\n### Data Import and Merging\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmerged_data <- readRDS(\"data/merged_2013_2014.rds\")\n\nmerged_n <- nrow(merged_data)\n```\n:::\n\n\nThe merged dataset contains 10,175\nparticipants. It integrates demographic, examination, and diabetes\nquestionnaire data. We then restrict the sample to adults (age ≥ 20) to\ndefine the analytic cohort used in subsequent analyses. A small\nproportion of records have missing values in BMI and diabetes status,\nwhich will be addressed later through multiple imputation.\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Preview of merged NHANES 2013–2014 dataset limited to analysis variables (source columns only).\n\n| RIDAGEYR| BMXBMI| RIAGENDR| RIDRETH1| DIQ010|\n|--------:|------:|--------:|--------:|------:|\n|       69|   26.7|        1|        4|      1|\n|       54|   28.6|        1|        3|      1|\n|       72|   28.9|        1|        3|      1|\n|        9|   17.1|        1|        3|      2|\n|       73|   19.7|        2|        3|      2|\n|       56|   41.7|        1|        1|      2|\n|        0|     NA|        1|        3|     NA|\n|       61|   35.7|        2|        3|      2|\n|       42|     NA|        1|        2|      2|\n|       56|   26.5|        2|        3|      2|\n\n\n:::\n:::\n\n\n### Variable Definitions\n\n-   **Response Variable:**\\\n    `diabetes_dx` (binary) represents a Type 2 diabetes diagnosis,\n    excluding gestational diabetes. It was derived from `DIQ010`\n    (“Doctor told you have diabetes”), while `DIQ050` (insulin use) was\n    excluded to prevent treatment-related confounding.\n\n-   **Predictor Variables:**\n\n    -   `BMXBMI` – Body Mass Index (kg/m\\^2), treated as continuous and\n        categorized into six BMI classes (`bmi_cat`).\\\n    -   `RIDAGEYR` – Age (continuous, 20–80 years)\\\n    -   `RIAGENDR` – Sex (factor, two levels)\\\n    -   `RIDRETH1` – Ethnicity (factor, five levels)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# -----------------------------\n# Variable descriptions (with `code` formatting for names)\n# -----------------------------\nvar_tbl <- tribble(\n  ~Variable,      ~Description,                                                                                                   ~Type,         ~Origin,\n  \"`diabetes_dx`\",\"Type 2 diabetes diagnosis (1 = Yes, 0 = No) derived from `DIQ010`; gestational diabetes excluded.\",           \"Categorical\", \"Derived from `DIQ010`\",\n  \"`age`\",        \"Age in years.\",                                                                                                \"Continuous\",  \"NHANES `RIDAGEYR`\",\n  \"`bmi`\",        \"Body Mass Index (kg/m^2) computed from measured height and weight.\",                                           \"Continuous\",  \"NHANES `BMXBMI`\",\n  \"`bmi_cat`\",    \"BMI categories: Underweight, Normal, Overweight, Obesity I–III (`Normal` is reference in models).\",            \"Categorical\", \"Derived from `bmi`\",\n  \"`sex`\",        \"Sex of participant (`Male`, `Female`).\",                                                                       \"Categorical\", \"NHANES `RIAGENDR`\",\n  \"`race`\", \"race/Ethnicity collapsed to four levels: White, Black, Hispanic, Other.\", \"Categorical\", \"Derived from `RIDRETH1`\",\n  \"`WTMEC2YR`\",   \"Examination sample weight for Mobile Examination Center participants.\",                                        \"Weight\",      \"NHANES design\",\n  \"`SDMVPSU`\",    \"Primary Sampling Unit used for variance estimation in the complex survey design.\",                             \"Design\",      \"NHANES design\",\n  \"`SDMVSTRA`\",   \"Stratum identifier used to define strata for the complex survey design.\",                                      \"Design\",      \"NHANES design\",\n  \"`age_c`\",      \"Centered and standardized age (z-score).\",                                                                     \"Continuous\",  \"Derived from `age`\",\n  \"`bmi_c`\",      \"Centered and standardized BMI (z-score).\",                                                                     \"Continuous\",  \"Derived from `bmi`\"\n)\n\nkbl(\n  var_tbl,\n  caption = \"Variable Descriptions: Adult Analytic Dataset\",\n  align = c(\"l\",\"l\",\"l\",\"l\"),\n  escape = FALSE\n) %>%\n  kable_styling(full_width = FALSE, position = \"center\", bootstrap_options = c(\"striped\",\"hover\")) %>%\n  group_rows(\"Analysis variables\", 1, 6) %>%              # <-- updated range (now 6 analysis rows)\n  group_rows(\"Survey design variables\", 7, 9) %>%\n  group_rows(\"Derived variables\", 10, 11)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\caption{\\label{tab:variables-table}Variable Descriptions: Adult Analytic Dataset}\n\\centering\n\\begin{tabular}[t]{l|l|l|l}\n\\hline\nVariable & Description & Type & Origin\\\\\n\\hline\n\\multicolumn{4}{l}{\\textbf{Analysis variables}}\\\\\n\\hline\n\\hspace{1em}`diabetes_dx` & Type 2 diabetes diagnosis (1 = Yes, 0 = No) derived from `DIQ010`; gestational diabetes excluded. & Categorical & Derived from `DIQ010`\\\\\n\\hline\n\\hspace{1em}`age` & Age in years. & Continuous & NHANES `RIDAGEYR`\\\\\n\\hline\n\\hspace{1em}`bmi` & Body Mass Index (kg/m^2) computed from measured height and weight. & Continuous & NHANES `BMXBMI`\\\\\n\\hline\n\\hspace{1em}`bmi_cat` & BMI categories: Underweight, Normal, Overweight, Obesity I–III (`Normal` is reference in models). & Categorical & Derived from `bmi`\\\\\n\\hline\n\\hspace{1em}`sex` & Sex of participant (`Male`, `Female`). & Categorical & NHANES `RIAGENDR`\\\\\n\\hline\n\\hspace{1em}`race` & race/Ethnicity collapsed to four levels: White, Black, Hispanic, Other. & Categorical & Derived from `RIDRETH1`\\\\\n\\hline\n\\multicolumn{4}{l}{\\textbf{Survey design variables}}\\\\\n\\hline\n\\hspace{1em}`WTMEC2YR` & Examination sample weight for Mobile Examination Center participants. & Weight & NHANES design\\\\\n\\hline\n\\hspace{1em}`SDMVPSU` & Primary Sampling Unit used for variance estimation in the complex survey design. & Design & NHANES design\\\\\n\\hline\n\\hspace{1em}`SDMVSTRA` & Stratum identifier used to define strata for the complex survey design. & Design & NHANES design\\\\\n\\hline\n\\multicolumn{4}{l}{\\textbf{Derived variables}}\\\\\n\\hline\n\\hspace{1em}`age_c` & Centered and standardized age (z-score). & Continuous & Derived from `age`\\\\\n\\hline\n\\hspace{1em}`bmi_c` & Centered and standardized BMI (z-score). & Continuous & Derived from `bmi`\\\\\n\\hline\n\\end{tabular}\n\\end{table}\n\n\n:::\n:::\n\n\n### Study Design and Survey-Weighted Analysis\n\nThe National Health and Nutrition Examination Survey (NHANES) employs a\ncomplex, multistage probability sampling design with stratification,\nclustering, and oversampling of specific demographic groups (for\nexample, racial/ethnic minorities and older adults) to produce\nnationally representative estimates of the U.S. population.\n\nSurvey design variables — primary sampling units (`SDMVPSU`), strata\n(`SDMVSTRA`), and examination sample weights (`WTMEC2YR`) — were\nretained to account for this complex design. These variables were\napplied to adjust for unequal probabilities of selection, nonresponse,\nand oversampling, ensuring valid standard errors, unbiased prevalence\nestimates, and generalizable population-level inference.\n\nA survey-weighted logistic regression model was used to evaluate the\nassociation between diabetes status (`diabetes_dx`, binary outcome) and\nkey predictors: body mass index (`bmi`), age (`age`), sex (`sex`), and\nrace/ethnicity (`race`). Diabetes was defined using `DIQ010` (“Doctor\ntold you have diabetes”) and coded as 0/1, with `DIQ050` (insulin use)\nexcluded to avoid treatment-related confounding.\n\nCovariates included:\\\n- `age` (continuous; centered as `age_c`, categorized 20–80 years)\\\n- `bmi` (continuous; centered as `bmi_c`, and categorized by BMI class\n`bmi_cat`)\\\n- `sex` (male, female)\\\n- `race` (four ethnicity levels: White, Black, Hispanic, Other)\n\nThis approach accounts for NHANES’ complex sampling design, producing\nunbiased parameter estimates and valid inference for U.S. adults.\n\n| Step | Description |\n|------------------------|------------------------------------------------|\n| **Weighting** | Used the **`survey`** package to calculate weighted means for key variables (e.g., age and diabetes status) and to estimate design effects and effective sample size for the complex survey design. |\n| **Standardization** | Centered and standardized BMI and age (`bmi_c`, `age_c`) for use in regression models. |\n| **Age Categorization** | Not implemented in the analytic dataset (continuous `age` retained). Reference retained for potential descriptive grouping (20–\\<30, 30–\\<40, 40–\\<50, 50–\\<60, 60–\\<70, 70–80). |\n| **BMI Categorization** | Recoded as: \\<18.5 (Underweight), 18.5–\\<25 (Normal), 25–\\<30 (Overweight), 30–\\<35 (Obesity I), 35–\\<40 (Obesity II), ≥40 (Obesity III). |\n| **Ethnicity Recoding** | `RIDRETH1` recoded as: 1 = Mexican American, 2 = Other Hispanic, 3 = Non-Hispanic White, 4 = Non-Hispanic Black, 5 = Other/Multi; then `NH White` set as the reference level (five analytical levels retained). |\n| **Special Codes** | Transformed nonresponse codes (e.g., 3, 7, 9) to `NA`. These missing codes were evaluated for potential nonrandom patterns (MAR/MNAR). |\n| **Missing Data** | Retained and visualized missing values (primarily in BMI and diabetes status) to assess their pattern and informativeness before multiple imputation. |\n| **Final Dataset** | Created the cleaned analytic dataset (`adult`) using *Non-Hispanic White* and *Male* as reference groups for modeling, preserving NHANES survey design variables (`WTMEC2YR`, `SDMVPSU`, `SDMVSTRA`). |\n\n\n\n### Adult Cohort Definition\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# NHANES survey design object for the adult analytic cohort\n\nnhanes_design_adult <- survey::svydesign(\nid      = ~SDMVPSU,\nstrata  = ~SDMVSTRA,\nweights = ~WTMEC2YR,\nnest    = TRUE,\ndata    = adult\n)\n\n# Quick weighted checks\n\nsurvey::svymean(~age, nhanes_design_adult, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      mean     SE\nage 47.496 0.3805\n```\n\n\n:::\n\n```{.r .cell-code}\nsurvey::svymean(~diabetes_dx, nhanes_design_adult, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                mean     SE\ndiabetes_dx 0.089016 0.0048\n```\n\n\n:::\n\n```{.r .cell-code}\n# Design effect and effective sample size for `diabetes_dx`\n\nv_hat <- as.numeric(survey::svyvar(~diabetes_dx, nhanes_design_adult, na.rm = TRUE))\np_hat <- mean(adult$diabetes_dx, na.rm = TRUE)\nn_obs <- nrow(adult)\nv_srs <- p_hat * (1 - p_hat) / n_obs\ndeff  <- v_hat / v_srs\n\nn_total <- sum(weights(nhanes_design_adult), na.rm = TRUE)\ness     <- as.numeric(n_total / deff)\n\ncat(\"Design effect for diabetes_dx:\", round(deff, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDesign effect for diabetes_dx: 4759.91 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Effective sample size for diabetes_dx:\", round(ess), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffective sample size for diabetes_dx: 48142 \n```\n\n\n:::\n:::\n\n\nDescriptive statistics for continuous and categorical variables are\npresented below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Keep only analytic variables for Table 1\ntbl1_dat <- adult %>%\n  transmute(\n    age,\n    bmi,\n    bmi_cat,\n    sex,\n    race,\n    diabetes_dx = factor(diabetes_dx, levels = c(0, 1), labels = c(\"No\", \"Yes\"))\n  )\n\n# Continuous summaries: N, missing, mean, sd, min, max\ncont_vars <- c(\"age\", \"bmi\")\n\ncont_sum <- tbl1_dat %>%\n  select(all_of(cont_vars)) %>%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"value\") %>%\n  group_by(Variable) %>%\n  summarise(\n    N       = sum(!is.na(value)),\n    Missing = sum(is.na(value)),\n    Mean    = round(mean(value, na.rm = TRUE), 2),\n    SD      = round(sd(value, na.rm = TRUE), 2),\n    Min     = round(min(value, na.rm = TRUE), 1),\n    Max     = round(max(value, na.rm = TRUE), 1),\n    .groups = \"drop\"\n  )\n\n# Categorical summaries: counts and percents\ncat_vars <- c(\"sex\", \"race\", \"diabetes_dx\", \"bmi_cat\")\n\ncat_sum <- tbl1_dat %>%\n  mutate(across(all_of(cat_vars),\n                ~ forcats::fct_explicit_na(as.factor(.x), na_level = \"(Missing)\"))) %>%\n  select(all_of(cat_vars)) %>%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Level\") %>%\n  count(Variable, Level, name = \"n\") %>%\n  group_by(Variable) %>%\n  mutate(pct = round(100 * n / sum(n), 1)) %>%\n  ungroup() %>%\n  arrange(Variable, desc(n))\n\n# Render tables\nkable(cont_sum,\n      caption = \"Table 1a. Continuous variables (age, BMI): N, missing, mean (SD), range.\") %>%\n  kable_styling(full_width = FALSE)\n```\n\n::: {.cell-output-display}\n\n\\begin{longtable}[t]{lrrrrrr}\n\\caption{\\label{tab:tbl1-analytic}Table 1a. Continuous variables (age, BMI): N, missing, mean (SD), range.}\\\\\n\\toprule\nVariable & N & Missing & Mean & SD & Min & Max\\\\\n\\midrule\nage & 5769 & 0 & 49.11 & 17.56 & 20.0 & 80.0\\\\\nbmi & 5520 & 249 & 29.10 & 7.15 & 14.1 & 82.9\\\\\n\\bottomrule\n\\end{longtable}\n\n\n:::\n\n```{.r .cell-code}\nkable(cat_sum,\n      caption = \"Table 1b. Categorical variables (sex, race, diabetes_dx, bmi_cat): counts and percentages.\") %>%\n  kable_styling(full_width = FALSE)\n```\n\n::: {.cell-output-display}\n\n\\begin{longtable}[t]{llrr}\n\\caption{\\label{tab:tbl1-analytic}Table 1b. Categorical variables (sex, race, diabetes_dx, bmi_cat): counts and percentages.}\\\\\n\\toprule\nVariable & Level & n & pct\\\\\n\\midrule\nbmi\\_cat & 25–<30 & 1768 & 30.6\\\\\nbmi\\_cat & 18.5–<25 & 1579 & 27.4\\\\\nbmi\\_cat & 30–<35 & 1145 & 19.8\\\\\nbmi\\_cat & 35–<40 & 519 & 9.0\\\\\nbmi\\_cat & ≥40 & 419 & 7.3\\\\\n\\addlinespace\nbmi\\_cat & (Missing) & 249 & 4.3\\\\\nbmi\\_cat & <18.5 & 90 & 1.6\\\\\ndiabetes\\_dx & No & 4974 & 86.2\\\\\ndiabetes\\_dx & Yes & 618 & 10.7\\\\\ndiabetes\\_dx & (Missing) & 177 & 3.1\\\\\n\\addlinespace\nrace & NH White & 2472 & 42.8\\\\\nrace & NH Black & 1177 & 20.4\\\\\nrace & Other/Multi & 845 & 14.6\\\\\nrace & Mexican American & 767 & 13.3\\\\\nrace & Other Hispanic & 508 & 8.8\\\\\n\\addlinespace\nsex & Female & 3011 & 52.2\\\\\nsex & Male & 2758 & 47.8\\\\\n\\bottomrule\n\\end{longtable}\n\n\n:::\n:::\n\n\nTable 1a and 1b summarize the analytic variables included in subsequent\nmodels. Mean age and BMI values indicate an adult cohort spanning a wide\nrange of body composition, while categorical summaries confirm balanced\nsex representation and sufficient sample sizes across race/ethnicity\ncategories. These variables were standardized and used as predictors in\nall modeling frameworks (analytic cohort N = 5,769 adults ≥ 20 years).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadult_n <- nrow(adult)\n```\n:::\n\n\n\n::: {#tbl-adult .cell tbl-cap='Excerpt of the cleaned NHANES 2013–2014 adult cohort (age ≥ 20; N = 5,769) with derived and standardized variables.'}\n::: {.cell-output-display}\n\n\n| SDMVPSU| SDMVSTRA| WTMEC2YR| diabetes_dx|  bmi| age|sex    |race             | DIQ050|     age_c|      bmi_c|bmi_cat  |\n|-------:|--------:|--------:|-----------:|----:|---:|:------|:----------------|------:|---------:|----------:|:--------|\n|       1|      112| 13481.04|           1| 26.7|  69|Male   |NH Black         |      1| 1.1324183| -0.3358861|25–<30   |\n|       1|      108| 24471.77|           1| 28.6|  54|Male   |NH White         |      1| 0.2783598| -0.0702810|25–<30   |\n|       1|      109| 57193.29|           1| 28.9|  72|Male   |NH White         |      1| 1.3032300| -0.0283434|25–<30   |\n|       2|      116| 65541.87|           0| 19.7|  73|Female |NH White         |      2| 1.3601672| -1.3144311|18.5–<25 |\n|       1|      111| 25344.99|           0| 41.7|  56|Male   |Mexican American |      2| 0.3922343|  1.7609961|≥40      |\n|       1|      114| 61758.65|           0| 35.7|  61|Female |NH White         |      2| 0.6769204|  0.9222432|35–<40   |\n\n\n:::\n:::\n\n\nAs shown in @tbl-adult, the analytic adult cohort (N =\n5,769) includes standardized variables for\nage and BMI (`age_c`, `bmi_c`), categorical indicators for sex and\nrace/ethnicity (`race`), and a binary doctor-diagnosed diabetes variable\n(`diabetes_dx`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Textual structure and preview\nstr(adult)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t5769 obs. of  12 variables:\n $ SDMVPSU    : num  1 1 1 2 1 1 2 1 2 2 ...\n $ SDMVSTRA   : num  112 108 109 116 111 114 106 112 112 113 ...\n $ WTMEC2YR   : num  13481 24472 57193 65542 25345 ...\n $ diabetes_dx: num  1 1 1 0 0 0 0 0 0 0 ...\n $ bmi        : num  26.7 28.6 28.9 19.7 41.7 35.7 NA 26.5 22 20.3 ...\n $ age        : num  69 54 72 73 56 61 42 56 65 26 ...\n $ sex        : Factor w/ 2 levels \"Male\",\"Female\": 1 1 1 2 1 2 1 2 1 2 ...\n $ race       : Factor w/ 5 levels \"NH White\",\"Mexican American\",..: 4 1 1 1 2 1 3 1 1 1 ...\n $ DIQ050     : num  1 1 1 2 2 2 2 2 2 2 ...\n $ age_c      : num  1.132 0.278 1.303 1.36 0.392 ...\n $ bmi_c      : num  -0.3359 -0.0703 -0.0283 -1.3144 1.761 ...\n $ bmi_cat    : Factor w/ 6 levels \"<18.5\",\"18.5–<25\",..: 3 3 3 2 6 5 NA 3 2 2 ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# Visual structure and type overview\nplot_intro(adult, title = \"Adult Dataset: Variable Types and Completeness\")\n```\n\n::: {.cell-output-display}\n![The visual overview indicates that 75% of variables are continuous and 25% are categorical, with no completely missing columns. Approximately 92.7% of rows are fully complete, and only 1.3% of observations contain missing values, suggesting minimal data loss prior to imputation.](index_files/figure-pdf/structure-and-preview-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n### Missing Data Summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize missing data pattern\nplot_missing(adult, title = \"Missing Data Pattern (Adult Dataset)\")\n```\n\n::: {.cell-output-display}\n![Missing data were minimal across analytic variables. BMI-related fields (bmi, bmi_c, bmi_cat) showed ~4.3% missingness, and diabetes_dx showed ~3.1%. All demographic and survey design variables were complete, indicating that missingness was limited to health-related measures and appropriate for multiple imputation.](index_files/figure-pdf/missingness-visual-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summarize missingness for key analysis variables\n\nmiss_tbl <- tibble::tibble(\nVariable    = c(\"bmi\", \"diabetes_dx\"),\nMissing_n   = c(sum(is.na(adult_eda$bmi)), sum(is.na(adult_eda$diabetes_dx))),\nMissing_pct = round(c(mean(is.na(adult_eda$bmi)), mean(is.na(adult_eda$diabetes_dx))) * 100, 1)\n)\n\nknitr::kable(\nmiss_tbl,\ncaption = \"Missingness for Key Analysis Variables.\"\n)\n```\n\n::: {.cell-output-display}\n\n\nTable: Missingness for Key Analysis Variables.\n\n|Variable    | Missing_n| Missing_pct|\n|:-----------|---------:|-----------:|\n|bmi         |       249|         4.3|\n|diabetes_dx |       177|         3.1|\n\n\n:::\n:::\n\n\nOverall missingness was low\n(\\~7.3%).\nGaps were concentrated in `bmi` (n = 249) and `diabetes_dx` (n = 177),\nwhile demographic and design variables were complete. This limited\npattern of missingness is consistent with a Missing At Random (MAR)\nmechanism and likely reflects reduced participation in the physical\nexamination component among certain adults.\n\n### Exploratory Data Analysis\n\nFollowing the missing data assessment, exploratory analyses were\nconducted to describe the adult analytic cohort and visualize\ndistributions across key demographic and health variables. The goal was\nto examine univariate patterns and bivariate relationships relevant to\ndiabetes prevalence prior to modeling.\n\nThe adult analytic cohort was broadly representative of the U.S.\npopulation, with a majority identifying as `Non-Hispanic White`. `Age`\nand `BMI` distributions were right-skewed, with most participants\nclassified as overweight or obese. Visual exploration revealed a clear\npositive association between `age`, `BMI`, and diabetes prevalence.\n`Non-Hispanic Black` and `Hispanic` participants exhibited higher\ndiabetes prevalence compared with `Non-Hispanic Whites`.\n\nApproximately 25% of variables were categorical (e.g., `sex`, `race`,\n`diabetes_dx`) and 75% were continuous (e.g., `age`, `bmi`, `age_c`,\n`bmi_c`), indicating that the dataset primarily comprised measured\nnumeric values. About 93% of observations contained complete information\nacross all predictors and outcomes, reflecting high data quality.\n\nAdult `age` ranged from 20 to 80 years, with peak representation between\n30 and 50 years and a slight right skew toward older ages. `BMI` was\nconcentrated in the overweight and obese ranges, and `Female`\nparticipants were slightly overrepresented relative to `Male`\nparticipants.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Age distribution (analytic adult)\nggplot(adult, aes(x = age)) +\n  geom_histogram(binwidth = 5, color = \"white\") +\n  labs(title = \"Distribution of Age (≥20 years)\", x = \"Age (years)\", y = \"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Distribution of age among adults aged ≥20 years. The sample spans 20–80 years, with peak representation between 30 and 50 years and a gradual decline in older age groups, reflecting a balanced adult cohort suitable for regression modeling.](index_files/figure-pdf/eda-age-distribution-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Diabetes outcome distribution\nggplot(adult, aes(x = factor(diabetes_dx, levels = c(0,1), labels = c(\"No\",\"Yes\")))) +\n  geom_bar() +\n  labs(title = \"Diabetes Outcome Distribution (≥20 years)\", x = \"Diabetes (No/Yes)\", y = \"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Distribution of diabetes outcomes among adults aged ≥20 years. Most participants reported no diabetes diagnosis (`No`), while approximately 11% had diabetes (`Yes`) and 3% had missing responses, reflecting expected population prevalence and limited outcome missingness.](index_files/figure-pdf/eda-diabetes-distribution-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# BMI category distribution\nggplot(adult, aes(x = bmi_cat)) +\n  geom_bar(color = \"white\", fill = \"skyblue\") +\n  labs(title = \"Distribution of BMI Categories (≥20 years)\", x = \"BMI Category\", y = \"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Distribution of BMI categories among adults aged ≥20 years. The majority of participants fell within the overweight (25–<30) and obese (≥30) ranges, with fewer individuals classified as underweight (<18.5). This distribution aligns with national trends in adult body composition, supporting the dataset’s representativeness for metabolic health analyses.](index_files/figure-pdf/eda-bmi-distribution-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# BMI by diabetes outcome (boxplot)\n# (You can’t use boxplot with categorical y, so revert to numeric BMI here)\nggplot(adult, aes(x = factor(diabetes_dx, levels = c(0,1), labels = c(\"No\",\"Yes\")), y = bmi)) +\n  geom_boxplot(fill = \"lightblue\") +\n  labs(title = \"BMI by Diabetes Diagnosis (≥20 years)\", x = \"Diabetes (No/Yes)\", y = \"BMI (numeric)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![Distribution of BMI by diabetes diagnosis among adults aged ≥20 years. Participants with diabetes (`Yes`) show a higher median BMI and greater variability compared to those without diabetes (`No`), supporting the established positive association between obesity and diabetes risk.](index_files/figure-pdf/eda-bmi-by-diabetes-outcome-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Diabetes by race (dodged bars)\nggplot(adult, aes(x = race, fill = factor(diabetes_dx, levels = c(0,1), labels = c(\"No\",\"Yes\")))) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Diabetes Diagnosis by race/Ethnicity (≥20 years)\",\n       x = \"race/Ethnicity (race)\", y = \"Count\", fill = \"Diabetes\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![Diabetes diagnosis by race/ethnicity among adults aged ≥20 years. Non-Hispanic Black and Hispanic participants show higher proportions of diabetes diagnoses compared with Non-Hispanic White participants, reflecting known disparities in diabetes prevalence across racial and ethnic groups.](index_files/figure-pdf/eda-diabetes-by-race-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n## Modeling Frameworks\n\nThree modeling frameworks were compared using identical\npredictors—standardized age, BMI, sex, and race—and the binary outcome\n`diabetes_dx`:\n\n(1) survey-weighted logistic regression to account for the NHANES\n    complex sampling design,\n\n(2) multiple imputation (MICE) to handle missing BMI values, and\n\n(3) Bayesian logistic regression with weakly informative priors to\n    quantify parameter uncertainty.\n\n### Survey-Weighted Logistic Regression (Design-Based MLE)\n\nThe NHANES 2013–2014 data use a complex, multistage probability design\ninvolving strata (`SDMVSTRA`), primary sampling units (PSUs; `SDMVPSU`),\nand examination weights (`WTMEC2YR`) to ensure nationally representative\nestimates [@nchs2014].\n\nEstimates are population-weighted using NHANES survey design variables\n(`WTMEC2YR`, `SDMVSTRA`, `SDMVPSU`). Odds ratios are reported per one\nstandard deviation (1 SD) increase in age and BMI, with reference groups\nMale and White.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadult_clean <- adult %>%\n  dplyr::mutate(\n    sex   = forcats::fct_drop(sex),\n    race = forcats::fct_drop(race),\n    age_c = as.numeric(age_c),\n    bmi_c = as.numeric(bmi_c)\n  ) %>%\n  dplyr::filter(\n    !is.na(diabetes_dx),\n    !is.na(age_c),\n    !is.na(bmi_c),\n    !is.na(sex),\n    !is.na(race)\n  )\n```\n:::\n\n\nBelow is a structure of the analytic dataset used for regression\nmodeling, showing variable names, types, and sample values (N = 5,349).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(adult_clean[, c(\"diabetes_dx\",\"sex\",\"race\",\"age_c\",\"bmi_c\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t5349 obs. of  5 variables:\n $ diabetes_dx: num  1 1 1 0 0 0 0 0 0 1 ...\n $ sex        : Factor w/ 2 levels \"Male\",\"Female\": 1 1 1 2 1 2 2 1 2 1 ...\n $ race       : Factor w/ 5 levels \"NH White\",\"Mexican American\",..: 4 1 1 1 2 1 1 1 1 1 ...\n $ age_c      : num  1.132 0.278 1.303 1.36 0.392 ...\n $ bmi_c      : num  -0.3359 -0.0703 -0.0283 -1.3144 1.761 ...\n```\n\n\n:::\n:::\n\n\n\n::: {.cell tbl-cap='Distribution of participants by sex (Male = 2,551; Female = 2,798) in the analytic cohort.'}\n\n```{.r .cell-code}\nknitr::kable(\n  table(adult_clean$sex)\n)\n```\n\n::: {.cell-output-display}\n\n\n|Var1   | Freq|\n|:------|----:|\n|Male   | 2551|\n|Female | 2798|\n\n\n:::\n:::\n\n\n\n::: {.cell tbl-cap='Race/ethnicity composition of the analytic cohort, with most participants identifying as Non-Hispanic White (n = 2,293) and Non-Hispanic Black (n = 1,101).'}\n\n```{.r .cell-code}\nknitr::kable(\n  table(adult_clean$race)\n)\n```\n\n::: {.cell-output-display}\n\n\n|Var1             | Freq|\n|:----------------|----:|\n|NH White         | 2293|\n|Mexican American |  713|\n|Other Hispanic   |  470|\n|NH Black         | 1101|\n|Other/Multi      |  772|\n\n\n:::\n:::\n\n\n\n::: {.cell tbl-cap='Observed diabetes prevalence (binary outcome variable `diabetes_dx`), with 597 diagnosed cases (1 = Yes) and 4,752 non-diabetic participants (0 = No).'}\n\n```{.r .cell-code}\nknitr::kable(\n  table(adult_clean$diabetes_dx)\n)\n```\n\n::: {.cell-output-display}\n\n\n|Var1 | Freq|\n|:----|----:|\n|0    | 4752|\n|1    |  597|\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(survey.lonely.psu = \"adjust\")\n\nnhanes_design_adult <- survey::svydesign(\n  id      = ~SDMVPSU,\n  strata  = ~SDMVSTRA,\n  weights = ~WTMEC2YR,\n  nest    = TRUE,\n  data    = adult_clean\n)\n\nsvy_fit <- survey::svyglm(\n  diabetes_dx ~ age_c + bmi_c + sex + race,\n  design = nhanes_design_adult,\n  family = quasibinomial()\n)\n\nsvy_or <- broom::tidy(svy_fit, conf.int = TRUE) %>%\n  dplyr::mutate(\n    OR  = exp(estimate),\n    LCL = exp(conf.low),\n    UCL = exp(conf.high)\n  ) %>%\n  dplyr::select(term, OR, LCL, UCL, p.value) %>%\n  dplyr::filter(term != \"(Intercept)\")\n```\n:::\n\n\n\n::: {#tbl-svylogit .cell tbl-cap='Survey-weighted logistic regression: odds ratios (OR) and 95% confidence intervals for diabetes diagnosis among adults (NHANES 2013–2014).'}\n\n```{.r .cell-code}\nknitr::kable(svy_or)\n```\n\n::: {.cell-output-display}\n\n\n|term                 |        OR|       LCL|       UCL|   p.value|\n|:--------------------|---------:|---------:|---------:|---------:|\n|age_c                | 3.0292807| 2.6967690| 3.4027912| 0.0000000|\n|bmi_c                | 1.8853571| 1.6526296| 2.1508579| 0.0000039|\n|sexFemale            | 0.5281132| 0.4104905| 0.6794397| 0.0003857|\n|raceMexican American | 2.0358434| 1.4850041| 2.7910081| 0.0008262|\n|raceOther Hispanic   | 1.5915182| 1.1664529| 2.1714810| 0.0087119|\n|raceNH Black         | 1.6689718| 1.1605895| 2.4000450| 0.0116773|\n|raceOther/Multi      | 2.3270527| 1.5451752| 3.5045697| 0.0014331|\n\n\n:::\n:::\n\n\n#### Interpretation\n\n`age_c` and `bmi_c` are the strongest predictors of diabetes in the\nNHANES 2013–2014 adult cohort, with each 1 SD increase in age nearly\ntripling the odds of diabetes and higher BMI substantially elevating\nrisk. Males show significantly lower odds of diabetes than females,\nconsistent with established sex differences in metabolic outcomes.\nRacial and ethnic disparities are evident, with Mexican American, Other\nHispanic, Non-Hispanic Black, and Other/Multi-racial adults all showing\nsignificantly higher odds of diabetes compared to Non-Hispanic Whites.\nAll predictors were statistically significant (p \\< 0.05), indicating\nrobust associations across demographic and health characteristics.\n\n### Multiple Imputation by Chained Equations\n\nMultiple Imputation by Chained Equations (`MICE`) was implemented as a\nprincipled approach for handling missing data [@vanbuuren2011;\n@vanbuuren2012]. `MICE` iteratively imputes each incomplete variable\nusing regression models based on other variables in the dataset,\ngenerating multiple completed datasets that incorporate uncertainty from\nthe imputation process. Estimates are subsequently pooled across\nimputations using Rubin’s rules to obtain final parameter estimates and\nconfidence intervals.\n\nAs an alternative to full Bayesian joint modeling, `MICE` provides an\nefficient and flexible framework for managing missing data through\nchained regression equations. For large sample sizes (`n ≥ 400`), even\nwith substantial missingness (up to 75%) in a single variable, `MICE`\nremains robust to non-normality—such as skewed, multimodal, or\nheavy-tailed distributions—without materially affecting mean structure\nestimation performance [@vanbuuren2012].\n\nIn this study, continuous variables were imputed using regression-based\nmethods: `age` via normal linear regression (`norm`) and `BMI` via\npredictive mean matching (`pmm`) to better preserve the empirical BMI\ndistribution. Categorical variables (`sex` and `race`) were imputed\nusing logistic and polytomous regression models, respectively. Diabetes\nstatus (`diabetes_dx`) was treated as an outcome variable and was\n**not** imputed. Twenty imputations were generated to minimize Monte\nCarlo error and ensure stable variance estimation.\n\n#### Convergence and Data Stability\n\nThe chained equation process showed stable convergence across\niterations, confirming reliable estimation of missing `BMI` (and, where\npresent, `age`) values. After applying `MICE`, the final imputed dataset\nincluded **n = 5,592 adults** with all key predictors completed.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadult_imp1 <- mice::complete(imp, 1) %>%\n  dplyr::mutate(\n    age_c  = as.numeric(scale(age)),\n    bmi_c  = as.numeric(scale(bmi)),\n    wt_norm = WTMEC2YR / mean(WTMEC2YR, na.rm = TRUE),\n    race = forcats::fct_relevel(race, \"NH White\"),\n    sex  = forcats::fct_relevel(sex,  \"Male\")\n  ) %>%\n  dplyr::filter(\n    !is.na(diabetes_dx),\n    !is.na(age_c),\n    !is.na(bmi_c),\n    !is.na(sex),\n    !is.na(race)\n  ) %>%\n  droplevels()\n\nglimpse(adult_imp1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 5,592\nColumns: 11\n$ diabetes_dx <dbl> 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ age         <dbl> 69, 54, 72, 73, 56, 61, 42, 56, 65, 26, 76, 33, 32, 38, 50~\n$ bmi         <dbl> 26.7, 28.6, 28.9, 19.7, 41.7, 35.7, 23.6, 26.5, 22.0, 20.3~\n$ sex         <fct> Male, Male, Male, Female, Male, Female, Male, Female, Male~\n$ race        <fct> NH Black, NH White, NH White, NH White, Mexican American, ~\n$ WTMEC2YR    <dbl> 13481.04, 24471.77, 57193.29, 65541.87, 25344.99, 61758.65~\n$ SDMVPSU     <dbl> 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2~\n$ SDMVSTRA    <dbl> 112, 108, 109, 116, 111, 114, 106, 112, 112, 113, 116, 114~\n$ age_c       <dbl> 1.13241831, 0.27835981, 1.30323001, 1.36016725, 0.39223428~\n$ bmi_c       <dbl> -0.33319172, -0.06755778, -0.02561558, -1.31184309, 1.7639~\n$ wt_norm     <dbl> 0.3393916, 0.6160884, 1.4398681, 1.6500477, 0.6380722, 1.5~\n```\n\n\n:::\n:::\n\n\n#### Descriptive Results (Imputed Dataset)\n\nAfter imputation, the analytic dataset contained approximately\n**5,500–5,600 adults**. The mean `age` was around **49 years** (SD ≈\n17), and the mean `BMI` was approximately **29** (SD ≈ 7). `Female`\nparticipants represented about **52%** of the sample, and the majority\nidentified as `Non-Hispanic White` (\\~43%). The estimated diabetes\nprevalence was **\\~11%**, consistent with population-level NHANES\nbenchmarks.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorrelation_matrix <- cor(adult_imp1[, c(\"diabetes_dx\", \"age\", \"bmi\")], use = \"complete.obs\", method = \"pearson\")\ncorrelation_melted <- melt(correlation_matrix)\n\nggplot(correlation_melted, aes(Var1, Var2, fill = value)) +\ngeom_tile(color = \"white\") +\nscale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0, name = \"Correlation\") +\ntheme_minimal() +\ntheme(axis.text.x = element_text(angle = 45, hjust = 1)) +\nlabs(title = \"Correlation Heatmap: Diabetes, Age, and BMI\")\n```\n\n::: {.cell-output-display}\n![Correlation heatmap showing positive associations among `diabetes_dx`, `age`, and `BMI`. Both `age` and `BMI` exhibit moderate positive correlations with diabetes diagnosis, consistent with known metabolic risk trends in the NHANES adult population.](index_files/figure-pdf/corr-heatmap-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(adult_imp1, aes(x = factor(diabetes_dx))) +\ngeom_bar(fill = \"steelblue\") +\nlabs(title = \"Diabetes Diagnosis Distribution\", x = \"Diabetes (0 = No, 1 = Yes)\", y = \"Count\") +\ntheme_minimal()\n```\n\n::: {.cell-output-display}\n![Distribution of diabetes diagnosis among adults (age ≥ 20 years). The majority of participants (≈ 89%) reported no diabetes diagnosis (`0`), while about 11% reported a positive diagnosis (`1`), consistent with NHANES population prevalence.](index_files/figure-pdf/diabetes-dist-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(adult_imp1, aes(x = factor(diabetes_dx), y = bmi, fill = factor(diabetes_dx))) +\ngeom_boxplot(alpha = 0.7) +\nscale_x_discrete(labels = c(\"0\" = \"No Diabetes\", \"1\" = \"Diabetes\")) +\nlabs(x = \"Diabetes Diagnosis\", y = \"BMI\", title = \"BMI Distribution by Diabetes Status\") +\ntheme_minimal() +\ntheme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![Boxplot of BMI by diabetes status (`No` vs `Diabetes`). This descriptive plot compares BMI distributions between groups, highlighting higher median BMI, greater spread, and more outliers in the diabetes group. It is used in the EDA to summarize group differences before modeling.](index_files/figure-pdf/bmi-diabetes-box-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nThe boxplot in Figure \\@ref(fig-bmi-diabetes-box) is **descriptive**: it summarizes the median, spread, and outliers in BMI for participants with and without diabetes. The visibly higher median and wider spread in the diabetes group reinforce the positive association between excess adiposity and diabetes risk seen in later regression models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(adult_imp1, aes(x = bmi, y = diabetes_dx)) +\ngeom_point(alpha = 0.2, position = position_jitter(height = 0.02)) +\ngeom_smooth(method = \"glm\", method.args = list(family = \"binomial\"), se = TRUE, color = \"blue\") +\nlabs(x = \"BMI\", y = \"Probability of Diabetes\", title = \"Predicted Probability of Diabetes vs BMI\") +\ntheme_minimal()\n```\n\n::: {.cell-output-display}\n![Predicted probability of diabetes as a function of BMI from a logistic regression model. This inferential plot visualizes the fitted relationship between BMI and diabetes risk: the smooth curve shows the modeled probability of diabetes, and the shaded band reflects uncertainty (95% confidence interval) around the fit.](index_files/figure-pdf/pred-bmi-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nIn contrast to the descriptive boxplot, Figure \\@ref(fig-pred-bmi) is **inferential**: it displays the regression-based fitted probability of diabetes across the BMI continuum. The non-linear, increasing curve and its confidence band summarize how modeled diabetes risk escalates with higher BMI.\n\n\n::: {#tbl-mice .cell}\n\n```{.r .cell-code}\nmiss_age  <- sum(is.na(mi_dat$age))\nmiss_bmiN <- sum(is.na(mi_dat$bmi))\n\nmi_caption <- if (miss_age > 0 && miss_bmiN > 0) {\n\"Multiple Imputation (MICE): pooled odds ratios (OR) and 95% confidence intervals after imputing missing age (normal) and BMI (PMM) (m = 20); diabetes status was not imputed.\"\n} else if (miss_bmiN > 0) {\n\"Multiple Imputation (MICE): pooled odds ratios (OR) and 95% confidence intervals after imputing missing BMI (PMM) (m = 20); diabetes status was not imputed.\"\n} else if (miss_age > 0) {\n\"Multiple Imputation (MICE): pooled odds ratios (OR) and 95% confidence intervals after imputing missing age (normal) (m = 20); diabetes status was not imputed.\"\n} else {\n\"Multiple Imputation (MICE): pooled odds ratios (OR) and 95% confidence intervals (no variables required imputation); diabetes status was not imputed.\"\n}\nmi_caption <- paste0(mi_caption, \" Odds ratios are per 1 SD for age and BMI.\")\n\nknitr::kable(mi_or, caption = mi_caption)\n```\n\n::: {.cell-output-display}\n\n\nTable: Multiple Imputation (MICE): pooled odds ratios (OR) and 95% confidence intervals after imputing missing BMI (PMM) (m = 20); diabetes status was not imputed. Odds ratios are per 1 SD for age and BMI.\n\n|   |term                 |        OR| std.error| statistic|       df|   p.value|       LCL|       UCL|  conf.low| conf.high|\n|:--|:--------------------|---------:|---------:|---------:|--------:|---------:|---------:|---------:|---------:|---------:|\n|2  |age_c                | 2.9038183| 0.0559473| 19.054108| 5520.446| 0.0000000| 2.6021752| 3.2404277| 2.6021752| 3.2404277|\n|3  |bmi_c                | 1.7278084| 0.0447339| 12.224604| 5148.557| 0.0000000| 1.5827382| 1.8861754| 1.5827382| 1.8861754|\n|4  |sexFemale            | 0.5391132| 0.0937913| -6.587282| 5551.660| 0.0000000| 0.4485669| 0.6479368| 0.4485669| 0.6479368|\n|5  |raceMexican American | 2.4296216| 0.1375046|  6.456041| 5472.583| 0.0000000| 1.8555327| 3.1813298| 1.8555327| 3.1813298|\n|6  |raceOther Hispanic   | 1.7518320| 0.1748554|  3.206433| 5573.987| 0.0013515| 1.2434346| 2.4680953| 1.2434346| 2.4680953|\n|7  |raceNH Black         | 1.9757793| 0.1198118|  5.683602| 5576.734| 0.0000000| 1.5621842| 2.4988753| 1.5621842| 2.4988753|\n|8  |raceOther/Multi      | 2.1120110| 0.1530066|  4.886328| 4749.963| 0.0000011| 1.5646727| 2.8508138| 1.5646727| 2.8508138|\n\n\n:::\n:::\n\n\n#### Interpretation\n\n-   `Age` and `BMI` are strong positive predictors of diabetes; each 1\n    SD increase substantially increases the odds of diagnosis.\\\n-   `Sex:` Females exhibit significantly lower odds of diabetes compared\n    to males.\\\n-   `Race/Ethnicity:` All non-White racial and ethnic groups demonstrate\n    higher odds of diabetes compared to Non-Hispanic Whites,\n    underscoring persistent disparities in diabetes risk.\\\n-   **Model Significance:** All predictors are statistically significant\n    (*p* \\< 0.05).\\\n-   **Model Robustness:** Results are consistent with those from the\n    survey-weighted model, confirming stability across imputation and\n    weighting approaches.\n\n### Bayesian Logistic Regression\n\nBayesian logistic regression was used to quantify parameter uncertainty\nand compare posterior estimates with the survey-weighted and MICE\nmodels. Weakly informative priors were applied to regularize estimates\nwhile preserving flexibility in inference.\n\n**Model Specifications:** - **Family:** Bernoulli with logit link\\\n- **Data:** `adult_imp1` (N = 5,592)\\\n- **Chains:** 4 (2,000 iterations each; 1,000 warmup)\\\n- **Adaptation delta:** 0.95\\\n- **Weights:** Normalized NHANES examination weights (`wt_norm`, mean ≈\n1.00, SD ≈ 0.79)\\\n- **Predictors:** Standardized `age`, `BMI`, `sex`, and `race`\n\n#### Define Model and Priors\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfml_bayes <- diabetes_dx | weights(wt_norm) ~ age_c + bmi_c + sex + race\n\npriors <- c(\n  brms::set_prior(\"normal(0, 2.5)\", class = \"b\"),\n  brms::set_prior(\"student_t(3, 0, 10)\", class = \"Intercept\")\n)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadult_long <- adult_imp1 %>%\ndplyr::select(bmi_c, age_c) %>%\ntidyr::pivot_longer(\ncols = dplyr::everything(),\nnames_to = \"Coefficient\",\nvalues_to = \"Value\"\n)\n\nggplot2::ggplot(adult_long, ggplot2::aes(x = Value, fill = Coefficient)) +\nggplot2::geom_density(alpha = 0.5) +\nggplot2::theme_minimal() +\nggplot2::labs(\ntitle = \"Distributions for Standardized Age and BMI (adult_imp1)\",\nx = \"Standardized value (z-score)\",\ny = \"Density\",\nfill = \"Coefficient\"\n)\n```\n\n::: {.cell-output-display}\n![Distribution of standardized age (`age_c`) and BMI (`bmi_c`) in the imputed dataset (`adult_imp1`). Both variables were mean-centered and scaled (z-scores) for inclusion in regression models. The overlapping density curves indicate approximate normality and comparable variance, supporting suitability for standardized coefficient estimation.](index_files/figure-pdf/dist-adult-std-age-bmi-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_draws <- tibble::tibble(\nterm = rep(c(\"Age (per 1 SD)\", \"BMI (per 1 SD)\"), each = 4000),\nvalue = c(\nstats::rnorm(4000, mean = 0, sd = 2.5),\nstats::rnorm(4000, mean = 0, sd = 2.5)\n)\n)\n\nggplot2::ggplot(prior_draws, ggplot2::aes(x = value, fill = term)) +\nggplot2::geom_density(alpha = 0.5) +\nggplot2::theme_minimal() +\nggplot2::labs(\ntitle = \"Prior Distributions for Age and BMI Coefficients\",\nx = \"Coefficient value\",\ny = \"Density\",\nfill = NULL\n)\n```\n\n::: {.cell-output-display}\n![Prior distributions for standardized age and BMI coefficients, assuming Normal(0, 2.5) priors. These weakly informative priors constrain extreme coefficient values while allowing flexibility in posterior estimation, ensuring regularization without strong bias.](index_files/figure-pdf/prior-age-bmi-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n#### Fit the Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\npriors <- c(\n  brms::set_prior(\"normal(0, 2.5)\", class = \"b\"),\n  brms::set_prior(\"student_t(3, 0, 10)\", class = \"Intercept\")\n)\n\nbayes_fit <- brms::brm(\n  formula = diabetes_dx | weights(wt_norm) ~ age_c + bmi_c + sex + race,\n  data    = adult_imp1,\n  family  = bernoulli(link = \"logit\"),\n  prior   = priors,\n  chains  = 4, iter = 2000, seed = 123,\n  control = list(adapt_delta = 0.95),\n  refresh = 0\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning MCMC with 4 sequential chains...\n\nChain 1 finished in 11.3 seconds.\nChain 2 finished in 10.4 seconds.\nChain 3 finished in 10.8 seconds.\nChain 4 finished in 11.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 11.0 seconds.\nTotal execution time: 44.4 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(bayes_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: diabetes_dx | weights(wt_norm) ~ age_c + bmi_c + sex + race \n   Data: adult_imp1 (Number of observations: 5592) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept              -2.66      0.09    -2.83    -2.50 1.00     3548     3512\nage_c                   1.10      0.06     0.98     1.22 1.00     2349     2618\nbmi_c                   0.63      0.05     0.54     0.72 1.00     3327     2826\nsexFemale              -0.66      0.10    -0.86    -0.47 1.00     3668     3124\nraceMexicanAmerican     0.69      0.17     0.34     1.03 1.00     3657     2821\nraceOtherHispanic       0.43      0.25    -0.07     0.89 1.00     4242     3014\nraceNHBlack             0.53      0.15     0.23     0.83 1.00     3809     3012\nraceOtherDMulti         0.81      0.19     0.45     1.18 1.00     3948     2809\n\nDraws were sampled using sample(hmc). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nBayesian logistic regression model fit summary for diabetes diagnosis\n(`diabetes_dx`) with standardized predictors (age, BMI, sex, and race)\nand normalized NHANES weights. All four MCMC chains (4,000 post-warmup\ndraws) converged successfully (`R̂ ≈ 1.00`), indicating stable estimation\nacross parameters.\n\n\n::: {.cell tbl-cap='Posterior estimates from Bayesian logistic regression predicting diabetes diagnosis (`diabetes_dx`) using standardized predictors. Coefficients represent log-odds per 1 SD increase in age and BMI, with reference categories Male and Non-Hispanic White. All `R̂` values are 1.00, and effective sample sizes (Bulk/Tail ESS) exceed 2,000, confirming excellent MCMC convergence.'}\n\n```{.r .cell-code}\n# Extract fixed effects and convert to odds ratios\nbayes_fixef <- brms::fixef(bayes_fit, summary = TRUE)\n\nbayes_or <- bayes_fixef %>%\n  as.data.frame() %>%\n  tibble::rownames_to_column(\"term\") %>%\n  dplyr::mutate(\n    OR  = exp(Estimate),\n    LCL = exp(Q2.5),\n    UCL = exp(Q97.5)\n  )\n```\n:::\n\n\n#### Posterior Odd Ratios (Main Results)\n\n\n::: {#tbl-bayes .cell}\n\n```{.r .cell-code}\nknitr::kable(\ndplyr::mutate(bayes_or, dplyr::across(c(OR, LCL, UCL), ~ round(.x, 2)))\n)\n```\n\n::: {.cell-output-display}\n\n\n|term                |   Estimate| Est.Error|       Q2.5|      Q97.5|   OR|  LCL|  UCL|\n|:-------------------|----------:|---------:|----------:|----------:|----:|----:|----:|\n|Intercept           | -2.6633187| 0.0868613| -2.8341138| -2.4958967| 0.07| 0.06| 0.08|\n|age_c               |  1.0968784| 0.0618886|  0.9783744|  1.2200119| 2.99| 2.66| 3.39|\n|bmi_c               |  0.6282273| 0.0467939|  0.5366821|  0.7199012| 1.87| 1.71| 2.05|\n|sexFemale           | -0.6624742| 0.1034594| -0.8645869| -0.4660003| 0.52| 0.42| 0.63|\n|raceMexicanAmerican |  0.6898163| 0.1710160|  0.3432716|  1.0298163| 1.99| 1.41| 2.80|\n|raceOtherHispanic   |  0.4252184| 0.2458586| -0.0669575|  0.8870126| 1.53| 0.94| 2.43|\n|raceNHBlack         |  0.5307334| 0.1524774|  0.2283617|  0.8328511| 1.70| 1.26| 2.30|\n|raceOtherDMulti     |  0.8143883| 0.1876762|  0.4467512|  1.1763335| 2.26| 1.56| 3.24|\n\n\n:::\n:::\n\n\n-   Age and BMI show strong positive associations with diabetes\n    (credible intervals exclude 1).\n\n-   Female sex shows lower odds than male (protective factor).\n\n-   Non-White racial groups have higher odds compared with Whites,\n    consistent with known disparities.\n\n-   All model parameters exhibit well-defined, unimodal posteriors with\n    narrow credible intervals.\n\n#### Diagnostics and Model Fit\n\n\n::: {#tbl-bayesR2 .cell tbl-cap='Bayesian R² Summary'}\n\n```{.r .cell-code}\nknitr::kable(as.data.frame(brms::bayes_R2(bayes_fit)))\n```\n\n::: {.cell-output-display}\n\n\n|   |  Estimate| Est.Error|     Q2.5|     Q97.5|\n|:--|---------:|---------:|--------:|---------:|\n|R2 | 0.1316278| 0.0123417| 0.107432| 0.1565549|\n\n\n:::\n:::\n\n\n\n::: {#tbl-mcmc-diagnostics .cell tbl-cap='MCMC Diagnostics (R-hat and Effective Sample Sizes) for Model Parameters'}\n\n```{.r .cell-code}\ndiag <- posterior::summarise_draws(bayes_fit, \"rhat\", \"ess_bulk\", \"ess_tail\")\n\ndiag_b <- diag |>\ndplyr::as_tibble() |>\ndplyr::filter(grepl(\"^b_\", .data$variable)) |>\ndplyr::transmute(\nParameter = .data$variable,\nRhat      = .data$rhat,\nBulk_ESS  = .data$ess_bulk,\nTail_ESS  = .data$ess_tail\n)\n\nknitr::kable(diag_b, digits = 1)\n```\n\n::: {.cell-output-display}\n\n\n|Parameter             | Rhat| Bulk_ESS| Tail_ESS|\n|:---------------------|----:|--------:|--------:|\n|b_Intercept           |    1|   3548.0|   3511.8|\n|b_age_c               |    1|   2349.3|   2617.8|\n|b_bmi_c               |    1|   3327.1|   2825.9|\n|b_sexFemale           |    1|   3668.1|   3123.7|\n|b_raceMexicanAmerican |    1|   3656.6|   2821.2|\n|b_raceOtherHispanic   |    1|   4242.3|   3013.5|\n|b_raceNHBlack         |    1|   3809.1|   3012.2|\n|b_raceOtherDMulti     |    1|   3947.9|   2809.1|\n\n\n:::\n:::\n\n\nAll parameters achieved R̂ ≈ 1.00 and effective sample sizes \\>2,000,\nindicating excellent convergence. The Bayesian R² ≈ 0.13, showing that\nage, BMI, sex, and race explain about 13% of diabetes variability.\n\n#### Model Comparison\n\n\n::: {.cell tbl-cap='Bayesian Model Comparison (LOO): Base Model vs. Reduced Models Without Race or Sex'}\n\n```{.r .cell-code}\ninvisible(capture.output({\nfit_no_race <- update(bayes_fit, formula = update(fml_bayes, . ~ . - race))\nfit_no_sex  <- update(bayes_fit, formula = update(fml_bayes, . ~ . - sex))\n}))\n\nloo_base    <- loo::loo(bayes_fit)\nloo_no_race <- loo::loo(fit_no_race)\nloo_no_sex  <- loo::loo(fit_no_sex)\n\ncmp_df <- as.data.frame(loo::loo_compare(loo_base, loo_no_race, loo_no_sex))\ncmp_df$Model <- rownames(cmp_df)\ncmp_df <- cmp_df[, c(\"Model\", setdiff(names(cmp_df), \"Model\"))]\n\nknitr::kable(\ncmp_df,\ncaption = \"LOO Comparison (higher elpd_loo indicates better predictive performance).\"\n)\n```\n\n::: {.cell-output-display}\n\n\nTable: LOO Comparison (higher elpd_loo indicates better predictive performance).\n\n|            |Model       | elpd_diff|  se_diff|  elpd_loo| se_elpd_loo|    p_loo|  se_p_loo|    looic| se_looic|\n|:-----------|:-----------|---------:|--------:|---------:|-----------:|--------:|---------:|--------:|--------:|\n|bayes_fit   |bayes_fit   |   0.00000| 0.000000| -1418.258|    56.42097| 8.732434| 0.5944729| 2836.517| 112.8419|\n|fit_no_race |fit_no_race | -14.43171| 6.367627| -1432.690|    53.98749| 5.223838| 0.3831466| 2865.380| 107.9750|\n|fit_no_sex  |fit_no_sex  | -20.04611| 8.205833| -1438.305|    57.31024| 7.359525| 0.5226182| 2876.609| 114.6205|\n\n\n:::\n:::\n\n\nModels excluding race or sex had lower expected log predictive density\n(`elpd`), confirming that both variables contribute meaningfully to\nmodel fit.\n\n#### Posterior Predictive Checks\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyobs <- adult_imp1$diabetes_dx\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::pp_check(bayes_fit, type = \"bars\", nsamples = 100)\n```\n\n::: {.cell-output-display}\n![Posterior Predictive Check: Observed vs. Replicated Outcome Distribution (Bars)](index_files/figure-pdf/fig-ppc-bars-1.pdf){#fig-ppc-bars fig-pos='H'}\n:::\n:::\n\n\nThe close alignment between observed (`y`) and replicated (`y_rep`)\noutcome distributions indicates that the Bayesian model reproduces the\nempirical data structure well.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyrep <- brms::posterior_predict(bayes_fit, ndraws = 400)\nbayesplot::ppc_stat(y = yobs, yrep = yrep, stat = \"mean\")\n```\n\n::: {.cell-output-display}\n![Posterior predictive check for the mean of the binary outcome, comparing the observed mean (`T(y)`) to replicated means (`T(y_rep)`) across posterior draws.](index_files/figure-pdf/fig-ppc-mean-1.pdf){#fig-ppc-mean fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyrep <- brms::posterior_predict(bayes_fit, ndraws = 400)\nbayesplot::ppc_stat(y = yobs, yrep = yrep, stat = \"sd\")\n```\n\n::: {.cell-output-display}\n![Posterior predictive check for the standard deviation of the binary outcome (`T(y)`) compared with replicated datasets (`T(y_rep)`).](index_files/figure-pdf/fig-ppc-sd-1.pdf){#fig-ppc-sd fig-pos='H'}\n:::\n:::\n\n\nThe posterior predictive checks demonstrate strong model calibration:\nsimulated variability closely aligns with the observed data, indicating\nthat the Bayesian model accurately captures both the mean and dispersion\nof the binary outcome.\n\n#### MCMC Diagnostics and Posterior Distributions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_areas(as.array(bayes_fit), regex_pars = \"^b_\", prob = 0.95)\n```\n\n::: {.cell-output-display}\n![Posterior distributions (95% credible mass) for slope parameters in the Bayesian logistic regression model.](index_files/figure-pdf/fig-mcmc-areas-1.pdf){#fig-mcmc-areas fig-pos='H'}\n:::\n:::\n\n\nAll posteriors appear unimodal and well‐centered, indicating stable\nestimation and strong convergence across parameters. Positive\ncoefficients (e.g., age, BMI) correspond to increased diabetes risk,\nwhile negative coefficients (e.g., female sex) indicate protective\nassociations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbayesplot::mcmc_trace(as.array(bayes_fit), regex_pars = \"^b_\")\n```\n\n::: {.cell-output-display}\n![Trace plots for slope parameters across four MCMC chains, demonstrating effective chain mixing and stationarity.](index_files/figure-pdf/fig-mcmc-trace-1.pdf){#fig-mcmc-trace fig-pos='H'}\n:::\n:::\n\n\nAll parameters exhibit well-mixed, stable trace patterns with no visible\ndrift, supporting convergence diagnostics (`R̂` ≈ 1.00). This confirms\nthat the posterior samples are representative and that the Bayesian\nmodel converged reliably.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npost_array <- posterior::as_draws_array(bayes_fit)\nbayesplot::mcmc_acf(post_array, pars = c(\"b_age_c\", \"b_bmi_c\"))\n```\n\n::: {.cell-output-display}\n![Autocorrelation plots for posterior samples of age and BMI coefficients, showing rapid decay of autocorrelation with lag. Low autocorrelation across lags confirms efficient MCMC sampling and good chain independence.](index_files/figure-pdf/fig-mcmc-acf-1.pdf){#fig-mcmc-acf fig-pos='H'}\n:::\n:::\n\n\n-   Trace, density, and autocorrelation plots confirm smooth chain\n    mixing, unimodal posteriors, and minimal autocorrelation across\n    samples.\n\n-   All four chains showed strong convergence with no signs of\n    divergence or non-stationarity.\n\n-   Trace plots revealed stable, overlapping chains with consistent\n    mixing across iterations, while autocorrelation decayed rapidly\n    toward zero, confirming efficient sampling and low dependency\n    between successive draws.\n\n-   Together with R̂ ≈ 1.00 and large effective sample sizes, these\n    diagnostics indicate a well-behaved posterior and reliable\n    inference.\n\n#### Prior vs. Posterior\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract posterior draws as a matrix, then convert to tibble\npost <- as_draws_matrix(bayes_fit) %>%   # safer than as_draws_df for manipulation\n  as.data.frame() %>%\n  select(b_bmi_c, b_age_c) %>%\n  pivot_longer(\n    everything(),\n    names_to = \"term\",\n    values_to = \"estimate\"\n  ) %>%\n  mutate(\n    term = case_when(\n      term == \"b_bmi_c\" ~ \"BMI (per 1 SD)\",\n      term == \"b_age_c\" ~ \"Age (per 1 SD)\"\n    ),\n    type = \"Posterior\"\n  )\nprior_draws <- tibble(\n  term = rep(c(\"BMI (per 1 SD)\", \"Age (per 1 SD)\"), each = 4000),\n  estimate = c(rnorm(4000, 0, 1), rnorm(4000, 0, 1)),\n  type = \"Prior\"\n)\ncombined_draws <- bind_rows(prior_draws, post)\n\nggplot(combined_draws, aes(x = estimate, fill = type)) +\n  geom_density(alpha = 0.4) +\n  facet_wrap(~ term, scales = \"free\", ncol = 2) +\n  theme_minimal(base_size = 13) +\n  labs(\n    title = \"Prior vs Posterior Distributions\",\n    x = \"Coefficient estimate\",\n    y = \"Density\",\n    fill = \"\"\n  )\n```\n\n::: {.cell-output-display}\n![Prior vs Posterior Distributions](index_files/figure-pdf/fig-prior-posterior-ggplot-2-1.pdf){#fig-prior-posterior-ggplot-2 fig-pos='H'}\n:::\n:::\n\n\nFor age and BMI, the posterior densities shift notably away from the\nN(0, 2.5) prior toward positive values and are narrower, indicating\nstrong information from the data; for sex, the posterior remains closer\nto the prior with more overlap, indicating weaker evidence.\n\nThe overlay of prior and posterior densities illustrates that\ninformative updates occurred primarily for BMI, age, and race\ncoefficients, which showed distinct posterior shifts relative to the\npriors. In contrast, weaker predictors such as sex displayed overlapping distributions, indicating that inference for those parameters was more influenced by prior uncertainty than by the observed data. This balance confirms appropriate regularization rather than overfitting.\n\n#### Model Fit and Calibration\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_mean <- colMeans(brms::posterior_epred(bayes_fit))\nggplot(data.frame(pred = pred_mean, obs = yobs),\naes(x = pred, y = obs)) +\ngeom_point(alpha = 0.15, position = position_jitter(height = 0.03)) +\ngeom_smooth(method = \"loess\", se = TRUE) +\nlabs(x = \"Mean predicted probability\", y = \"Observed diabetes (0/1)\")\n```\n\n::: {.cell-output-display}\n![Calibration plot comparing observed diabetes outcomes (0/1) to model-predicted probabilities with a smoothed LOESS curve. The close alignment between the blue line and the diagonal (ideal calibration) indicates good model fit and reliable probability estimates.](index_files/figure-pdf/fig-pred-calibration-1.pdf){#fig-pred-calibration fig-pos='H'}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Survey-weighted prevalence\nsvy_mean <- svymean(~diabetes_dx, nhanes_design_adult, na.rm = TRUE)\n\n# 2. Posterior predictive prevalence (per draw)\npp_samples <- brms::posterior_predict(bayes_fit, ndraws = 1000)  # draws x individuals\npp_proportion <- rowMeans(pp_samples)                            # prevalence per draw\n\n# 3. Build comparison table\nsummary_table <- tibble(\n  Method = c(\"Survey-weighted mean (NHANES)\", \n             \"Imputed dataset mean\", \n             \"Posterior predictive mean\"),\n  diabetes_mean = c(\n    coef(svy_mean),                           # survey-weighted mean\n    mean(adult_imp1$diabetes_dx, na.rm = TRUE),  # imputed dataset\n    mean(pp_proportion)                       # posterior predictive mean\n  ),\n  SE = c(\n    SE(svy_mean),   # survey-weighted SE\n    NA,             # not available for raw mean\n    NA              # not available for posterior predictive mean\n  )\n)\n\nkable(summary_table, digits = 4,\n      caption = \"Comparison of Diabetes Prevalence Across Methods\")\n```\n\n::: {#fig-posterior-prevalence .cell-output-display}\n\n\nTable: Comparison of Diabetes Prevalence Across Methods\n\n|Method                        | diabetes_mean|     SE|\n|:-----------------------------|-------------:|------:|\n|Survey-weighted mean (NHANES) |        0.0889| 0.0048|\n|Imputed dataset mean          |        0.1105|     NA|\n|Posterior predictive mean     |        0.1093|     NA|\n\n\n\nComparison of diabetes prevalence across survey-weighted (NHANES), imputed, and posterior predictive estimates. The posterior predictive mean aligns closely with the observed NHANES prevalence, indicating strong model calibration.\n:::\n:::\n\n\nThe posterior predictive distribution of diabetes prevalence closely\nmirrored the survey-estimated prevalence, with the posterior mean\naligning within about 1% of the observed rate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior predictive prevalence (replicated datasets)\n\nyrep <- brms::posterior_predict(bayes_fit, ndraws = 2000)   # draws x observations (0/1)\npost_prev <- rowMeans(yrep)                                 # prevalence each posterior draw\n\n# Survey-weighted observed prevalence (population estimate)\n\ndes_obs <- survey::svydesign(\nid = ~SDMVPSU, strata = ~SDMVSTRA, weights = ~WTMEC2YR,\nnest = TRUE, data = adult_imp1\n)\nobs <- survey::svymean(~diabetes_dx, des_obs, na.rm = TRUE)\nobs_prev  <- as.numeric(obs[\"diabetes_dx\"])\nobs_se    <- as.numeric(SE(obs)[\"diabetes_dx\"])\nobs_lcl   <- max(0, obs_prev - 1.96 * obs_se)\nobs_ucl   <- min(1, obs_prev + 1.96 * obs_se)\n\n# Plot: posterior density with weighted point estimate and 95% CI band\n\nggplot(data.frame(prev = post_prev), aes(x = prev)) +\ngeom_density(alpha = 0.6) +\nannotate(\"rect\", xmin = obs_lcl, xmax = obs_ucl, ymin = 0, ymax = Inf, alpha = 0.15) +\ngeom_vline(xintercept = obs_prev, linetype = 2) +\ncoord_cartesian(xlim = c(0, 1)) +\nlabs(\n  x = \"Diabetes prevalence\",\n  y = \"Posterior density\",\n  subtitle = sprintf(\"Survey-weighted NHANES prevalence = %.1f%%\", obs_prev * 100)\n) +\ntheme_minimal()\n```\n\n::: {.cell-output-display}\n![Posterior predictive distribution of diabetes prevalence (solid density) overlaid with the survey-weighted NHANES prevalence (vertical dashed line) and its 95% confidence interval (shaded band). The close overlap indicates that the Bayesian model accurately reproduces the observed population prevalence.](index_files/figure-pdf/fig-pop-vs-posterior-prev-1.pdf){#fig-pop-vs-posterior-prev fig-pos='H'}\n:::\n:::\n\n\nThe survey-weighted NHANES diabetes prevalence was approximately **8.9%**, whereas the Bayesian model’s posterior predictive mean prevalence was also in the **8–9%** range. This close agreement indicates that the Bayesian logistic regression model reproduces the observed population-level prevalence and is well-calibrated to the NHANES data.\n\n\n::: {.cell tbl-cap='Comparison of diabetes prevalence estimates across methods. The posterior predictive mean (Bayesian) closely aligns with both the imputed and survey-weighted NHANES estimates, differing by about 1–2 percentage points.'}\n\n```{.r .cell-code}\n# Survey-weighted prevalence (already computed earlier as `obs`)\n\nobs_prev <- as.numeric(obs[\"diabetes_dx\"])\nobs_se   <- as.numeric(survey::SE(obs)[\"diabetes_dx\"])\n\nsummary_table <- tibble::tibble(\nMethod = c(\n\"Survey-weighted mean (NHANES)\",\n\"Imputed dataset mean (adult_imp1)\",\n\"Posterior predictive mean (Bayesian)\"\n),\ndiabetes_mean = c(\nobs_prev,\nmean(adult_imp1$diabetes_dx, na.rm = TRUE),\nmean(pp_proportion)\n),\nSE = c(\nobs_se,\nNA_real_,\nNA_real_\n)\n)\n\nknitr::kable(\nsummary_table,\ndigits = 4,\ncaption = \"Comparison of Diabetes Prevalence Across Methods\"\n)\n```\n\n::: {.cell-output-display}\n\n\nTable: Comparison of Diabetes Prevalence Across Methods\n\n|Method                               | diabetes_mean| SE|\n|:------------------------------------|-------------:|--:|\n|Survey-weighted mean (NHANES)        |        0.0890| NA|\n|Imputed dataset mean (adult_imp1)    |        0.1105| NA|\n|Posterior predictive mean (Bayesian) |        0.1093| NA|\n\n\n:::\n:::\n\n\n#### Internal Validation: Individual-Level Predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadult_means <- adult_imp1 %>% summarise(\nage_mean = mean(age, na.rm = TRUE),\nage_sd   = sd(age, na.rm = TRUE),\nbmi_mean = mean(bmi, na.rm = TRUE),\nbmi_sd   = sd(bmi, na.rm = TRUE)\n)\n\nto_model_row <- function(age_raw, bmi_raw, sex_lab, race_lab) {\ntibble(\nage_c  = (age_raw - adult_means$age_mean)/adult_means$age_sd,\nbmi_c  = (bmi_raw - adult_means$bmi_mean)/adult_means$bmi_sd,\nsex    = factor(sex_lab,   levels = levels(adult_imp1$sex)),\nrace  = factor(race_lab, levels = levels(adult_imp1$race)),\nwt_norm = 1\n)\n}\n\nplot_post_density <- function(df_row, title_txt) {\nphat <- posterior_linpred(bayes_fit, newdata = df_row, transform = TRUE)\nci95 <- quantile(phat, c(0.025, 0.975))\nggplot(data.frame(pred = as.numeric(phat)), aes(x = pred)) +\ngeom_density(fill = \"skyblue\", alpha = 0.4) +\ngeom_vline(xintercept = ci95[1], linetype = \"dashed\", color = \"red\") +\ngeom_vline(xintercept = ci95[2], linetype = \"dashed\", color = \"red\") +\nlabs(x = \"P(Diabetes = 1)\", y = \"Density\", title = title_txt) +\ntheme_minimal()\n}\n\np1 <- to_model_row(adult$age[1], adult$bmi[1],\nas.character(adult$sex[1]), as.character(adult$race[1]))\nplot_post_density(p1, \"Participant 1: Posterior Predictive Distribution (95% CrI)\")\n```\n\n::: {.cell-output-display}\n![Posterior predictive distribution for an example participant, showing the estimated probability of diabetes (P = 1) with 95% credible intervals (red dashed lines).](index_files/figure-pdf/posterior-density-participants-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nPosterior predictive densities for individual participants illustrate the uncertainty in diabetes risk estimates. The credible intervals quantify plausible risk ranges, emphasizing how posterior variability captures uncertainty rather than single-point predictions.\n\n#### Posterior Predictions and Inverse Inference\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# 1. Grid of BMI values (RAW BMI from 18 to 40)\nbmi_seq <- seq(18, 40, by = 0.5)\n\n# 2. Newdata using the SAME factor levels as adult_imp1\nnewdata_grid <- data.frame(\n  age_c  = 40,   # NOTE: Namita used 40 here even though age_c is standardized\n  bmi_c  = bmi_seq,   # she also used raw BMI in a column named bmi_c\n  sex    = factor(\"Female\",          levels = levels(adult_imp1$sex)),\n  race   = factor(\"Mexican American\", levels = levels(adult_imp1$race)),\n  wt_norm = 1\n)\n\n# 3. Posterior predicted probabilities\npred_probs <- brms::posterior_linpred(\n  bayes_fit,\n  newdata   = newdata_grid,\n  transform = TRUE\n)\n\n# 4. Mean predicted probability at each BMI\nprob_mean <- colMeans(pred_probs)\n\npred_df <- dplyr::bind_cols(newdata_grid, prob_mean = prob_mean)\n\n# 5. Target probability\ntarget_prob <- 0.30\n\n# Find the BMI whose predicted prob is closest to the target\nclosest <- pred_df[which.min(abs(pred_df$prob_mean - target_prob)), , drop = FALSE]\n\n# 6. Plot\nggplot(pred_df, aes(x = bmi_c, y = prob_mean)) +\n  geom_line(color = \"darkblue\", linewidth = 1.2) +\n  geom_hline(yintercept = target_prob, color = \"red\", linetype = \"dashed\") +\n  geom_vline(xintercept = closest$bmi_c, color = \"red\", linetype = \"dotted\") +\n  annotate(\n    \"text\",\n    x     = closest$bmi_c,\n    y     = target_prob + 0.05,\n    label = paste0(\"Target BMI \\u2248 \", round(closest$bmi_c, 1)),\n    color = \"red\",\n    hjust = -0.1\n  ) +\n  labs(\n    x = \"BMI (kg/m^2)\",\n    y = \"Predicted Probability of Diabetes\",\n    title = \"Inverse Prediction: BMI Needed for Target Diabetes Risk\"\n  ) +\n  coord_cartesian(ylim = c(0, 1)) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![Inverse prediction of BMI needed to reach a target diabetes probability (illustrative example).](index_files/figure-pdf/predict-BMI-target-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nInverse inference explores what BMI value would yield a given diabetes risk under the posterior model. In this example, predicted diabetes probability remains near 1.0 across most BMI values, suggesting that other covariates (e.g., age or race) dominate predicted risk in this profile. The “target BMI ≈ 18” marks the approximate threshold for a 30% risk under this participant’s conditions.\n\n## Results\n\nA concise summary of posterior estimates is provided below.\n\n\n\n\n```{.r .cell-code}\ncat(paste(bullets, collapse = \"\\n\"))\n```\n\n### Population-level interpretation (posterior, odds ratios)\n - **Convergence.** All R-hat ≈ 1.00; large ESS → excellent mixing.\n - **Baseline risk.** Male, White, mean age/BMI: **~6.5%** predicted diabetes prevalence.\n - **Age.** +1 SD → **2.99×** (95% CrI 2.66–3.39; CrI excludes 1).\n - **BMI.** +1 SD → **1.87×** (95% CrI 1.71–2.05; CrI excludes 1).\n - **Female vs. Male.** **0.52×** (95% CrI 0.42–0.63; CrI excludes 1).\n - **Black vs. White.** **NA×** (95% CrI NA–NA; CrI overlaps 1).\n - **Hispanic vs. White.** **NA×** (95% CrI NA–NA; CrI overlaps 1).\n - **Other/Multi vs. White.** **NA×** (95% CrI NA–NA; CrI overlaps 1).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine results from all three models\n\nsvy_tbl   <- if (exists(\"svy_or\") && nrow(svy_or) > 0)\ndplyr::mutate(svy_or,   Model = \"Survey-weighted (MLE)\") else NULL\nmi_tbl    <- if (exists(\"mi_or\") && nrow(mi_or) > 0)\ndplyr::mutate(mi_or,    Model = \"MICE Pooled\") else NULL\nbayes_tbl <- if (exists(\"bayes_or\") && nrow(bayes_or) > 0)\ndplyr::mutate(bayes_or, Model = \"Bayesian\") %>%\ndplyr::filter(term != \"Intercept\") else NULL\n\nall_tbl <- dplyr::bind_rows(Filter(Negate(is.null), list(svy_tbl, mi_tbl, bayes_tbl))) %>%\ndplyr::mutate(\nterm = dplyr::case_when(\n  grepl(\"bmi\", term,  ignore.case = TRUE) ~ \"BMI (per 1 SD)\",\n  grepl(\"age\", term,  ignore.case = TRUE) ~ \"Age (per 1 SD)\",\n  grepl(\"^sexFemale$\", term)              ~ \"Female (vs. Male)\",\n  grepl(\"^sexMale$\", term)                ~ \"Male (vs. Female)\",\n  grepl(\"^raceHispanic$\", term)          ~ \"Hispanic (vs. White)\",\n  grepl(\"^raceBlack$\", term)             ~ \"Black (vs. White)\",\n  grepl(\"^raceOther$\", term)             ~ \"Other (vs. White)\",\n  TRUE ~ term\n),\nOR_CI = sprintf(\"%.2f (%.2f – %.2f)\", OR, LCL, UCL)\n) %>%\ndplyr::select(Model, term, OR_CI)\n```\n:::\n\n\n\n::: {#tbl-comparison .cell tbl-cap='Comparison of odds ratios (per 1 SD for age and BMI) and 95% intervals across survey-weighted, MICE, and Bayesian frameworks.'}\n\n```{.r .cell-code}\nknitr::kable(all_tbl, align = c(\"l\",\"l\",\"c\"))\n```\n\n::: {.cell-output-display}\n\n\n|Model                 |term                 |       OR_CI        |\n|:---------------------|:--------------------|:------------------:|\n|Survey-weighted (MLE) |Age (per 1 SD)       | 3.03 (2.70 – 3.40) |\n|Survey-weighted (MLE) |BMI (per 1 SD)       | 1.89 (1.65 – 2.15) |\n|Survey-weighted (MLE) |Female (vs. Male)    | 0.53 (0.41 – 0.68) |\n|Survey-weighted (MLE) |raceMexican American | 2.04 (1.49 – 2.79) |\n|Survey-weighted (MLE) |raceOther Hispanic   | 1.59 (1.17 – 2.17) |\n|Survey-weighted (MLE) |raceNH Black         | 1.67 (1.16 – 2.40) |\n|Survey-weighted (MLE) |raceOther/Multi      | 2.33 (1.55 – 3.50) |\n|MICE Pooled           |Age (per 1 SD)       | 2.90 (2.60 – 3.24) |\n|MICE Pooled           |BMI (per 1 SD)       | 1.73 (1.58 – 1.89) |\n|MICE Pooled           |Female (vs. Male)    | 0.54 (0.45 – 0.65) |\n|MICE Pooled           |raceMexican American | 2.43 (1.86 – 3.18) |\n|MICE Pooled           |raceOther Hispanic   | 1.75 (1.24 – 2.47) |\n|MICE Pooled           |raceNH Black         | 1.98 (1.56 – 2.50) |\n|MICE Pooled           |raceOther/Multi      | 2.11 (1.56 – 2.85) |\n|Bayesian              |Age (per 1 SD)       | 2.99 (2.66 – 3.39) |\n|Bayesian              |BMI (per 1 SD)       | 1.87 (1.71 – 2.05) |\n|Bayesian              |Female (vs. Male)    | 0.52 (0.42 – 0.63) |\n|Bayesian              |raceMexicanAmerican  | 1.99 (1.41 – 2.80) |\n|Bayesian              |raceOtherHispanic    | 1.53 (0.94 – 2.43) |\n|Bayesian              |raceNHBlack          | 1.70 (1.26 – 2.30) |\n|Bayesian              |raceOtherDMulti      | 2.26 (1.56 – 3.24) |\n\n\n:::\n:::\n\n\nAcross all three frameworks—survey-weighted (MLE), multiple imputation,\nand Bayesian—age and BMI were consistently associated with higher odds\nof doctor-diagnosed diabetes. Female sex showed a lower odds ratio\ncompared to males, and both Black and Hispanic participants demonstrated elevated odds relative to White participants. The similarity of effect sizes across frameworks underscores the robustness of these predictors to different modeling assumptions and missing-data treatments.\n\n## Discussion and Limitations\n\n### Interpretation\n\nThe Bayesian logistic regression framework produced results that were\nhighly consistent with both the survey-weighted and MICE-pooled\nfrequentist models. Age and BMI remained the most influential predictors of doctor-diagnosed diabetes, each showing a strong and positive association with diabetes risk.\n\nUnlike classical maximum likelihood estimation, the Bayesian approach\ndirectly quantified uncertainty through posterior distributions,\noffering richer interpretability and more transparent probability\nstatements. The alignment between Bayesian and design-based estimates\nsupports the robustness of these associations and highlights the\npracticality of Bayesian modeling for complex, weighted population data.\n\nPosterior predictive checks confirmed that simulated diabetes prevalence closely matched the observed NHANES estimate, supporting good model calibration. This agreement reinforces that the priors were\nappropriately weakly informative and that inference was primarily driven by the observed data rather than prior specification.\n\nOverall, this study demonstrates that Bayesian inference complements\ntraditional epidemiologic methods by maintaining interpretability while\nenhancing stability and explicitly quantifying uncertainty in complex\nsurvey data.\n\n### Limitations\n\nWhile this analysis demonstrates the value of Bayesian logistic\nregression for epidemiologic modeling, several limitations should be\nacknowledged.\n\nFirst, the use of a single imputed dataset for the Bayesian model—rather\nthan full joint modeling of imputation uncertainty—may understate total\nvariance.\n\nSecond, NHANES exam weights were normalized and treated as importance\nweights, which approximate but do not fully reproduce design-based\ninference.\n\nThird, the weakly informative priors $N(0, 2.5)$ for slopes and\nStudent-t(3, 0, 10) for the intercept were not empirically tuned;\nalternative prior specifications could slightly alter posterior\nintervals.\n\nFinally, although convergence diagnostics (R̂ ≈ 1, sufficient effective\nsample sizes, and stable posterior predictive checks) indicated good\nmodel performance, results are conditional on the 2013–2014 NHANES cycle and may not generalize to later datasets or longitudinal analyses.\n\nIn addition, the model has not yet undergone external validation or\nformal sensitivity analyses. The participant-level posterior risk\nestimates presented in the internal validation section are illustrative\nonly and should not be used for individual decision-making or\nimplementation. Before deployment or use for imputation in other\nsettings, the model would require external validation in independent\ndatasets and sensitivity analyses to assess robustness to modeling and\nprior choices.\n\n## Conclusion\n\nThe Bayesian, survey-weighted, and imputed logistic regression\nframeworks all identified consistent predictors of diabetes risk in U.S. adults: advancing age, higher BMI, sex (lower odds for females), and non-White race/ethnicity.\n\nThe Bayesian model produced estimates nearly identical in direction and\nmagnitude to the frequentist results while providing a more\ncomprehensive assessment of uncertainty through posterior distributions\nand credible intervals.\n\nThese consistent findings across modeling frameworks underscore the\nrobustness of core risk factors and support the use of Bayesian\ninference for epidemiologic research involving complex survey data.\n\nBy incorporating prior information and using MCMC to sample from the\nfull posterior distribution, Bayesian inference enhances model\ntransparency and interpretability. Future extensions could integrate\nhierarchical priors, multiple NHANES cycles, or Bayesian model averaging to better capture population heterogeneity, temporal trends, and evolving diabetes risk patterns.\n",
    "supporting": [
      "index_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "\\usepackage{booktabs}\n\\usepackage{longtable}\n\\usepackage{array}\n\\usepackage{multirow}\n\\usepackage{wrapfig}\n\\usepackage{float}\n\\usepackage{colortbl}\n\\usepackage{pdflscape}\n\\usepackage{tabu}\n\\usepackage{threeparttable}\n\\usepackage{threeparttablex}\n\\usepackage[normalem]{ulem}\n\\usepackage{makecell}\n\\usepackage{xcolor}\n"
      ]
    },
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}