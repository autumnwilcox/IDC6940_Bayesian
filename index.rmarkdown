---
title: "Bayesian Logistic Regression for Predicting Diabetes Risk Using NHANES 2013–2014 Data"
subtitle: "A Capstone Project on Bayesian Applications in Epidemiologic Modeling"
author:
  - "Namita Mishra"
  - "Autumn Wilcox"
  - "Ecil Teodoro"
advisor: "Dr. Ashraf Cohen"
date: '`r Sys.Date()`'
course: Capstone Projects in Data Science

format:
  html:
    code-fold: true
    toc: true

bibliography: references.bib
reference-section-title: "References"
link-citations: true
self-contained: true

execute:
  warning: false
  message: false

editor:
  markdown:
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} (Edit `slides.qmd`.)

## Group Project Workflow and Contributions

This project was developed collaboratively as part of the Capstone Projects in Data Science course under the guidance of Dr. Ashraf Cohen. The team followed an iterative workflow encompassing data preparation, model development, validation, and documentation using GitHub for version control and collaborative editing.

- Autumn Wilcox – Contributed to analytic coding, content drafting, and structured the overall project workflow. Led documentation efforts and coordinated GitHub updates.
- Namita Mishra – Developed the initial project plan, conducted Bayesian model implementation, and integrated analytic code with visual diagnostics and posterior checks.
- Ecil Teodoro – Drafted sections of the Introduction and assisted in literature review and editing for clarity and cohesion.

## Introduction
Diabetes mellitus (DM) remains a major public health challenge, and identifying key risk factors—such as obesity, age, sex, and race/ethnicity—is essential for prevention and targeted intervention. Logistic regression is widely used to estimate associations between such factors and binary outcomes like diabetes diagnosis. However, classical maximum likelihood estimation (MLE) can produce unstable estimates in the presence of missing data, quasi-separation, or small samples. Bayesian logistic regression offers a robust alternative by integrating prior information, regularizing estimates, and quantifying uncertainty more transparently than frequentist approaches.

In this project, we apply Bayesian logistic regression to the 2013–2014 National Health and Nutrition Examination Survey (NHANES) dataset to examine the association between demographic and anthropometric factors and doctor-diagnosed diabetes. Our objective is to evaluate whether Bayesian inference provides more stable and interpretable estimates than frequentist baselines when data complexity or separation challenges arise.

Bayesian hierarchical models, implemented via Markov Chain Monte Carlo (MCMC), have been successfully applied in predicting patient health status across diseases such as pneumonia, prostate cancer, and mental disorders [@zeger2020]. By representing predictive uncertainty alongside point estimates, Bayesian inference offers a practical advantage in epidemiologic modeling where decisions hinge on probabilistic thresholds. Beyond stability, Bayesian methods support model checking, variable selection, and uncertainty quantification under missingness or imputation frameworks [@baldwin2017; @kruschke2017].

Recent work has expanded Bayesian applications to disease diagnostics and health risk modeling. For instance, Bayesian approaches have been used to evaluate NHANES diagnostic data [@chatzimichail2023], to model cardiovascular and metabolic risk [@liu2013], and to integrate multiple data modalities such as imaging and laboratory measures [@abdullah2022bdlhealth]. Moreover, multiple imputation combined with Bayesian modeling generates robust estimates when data are missing at random (MAR) or not at random (MNAR) [@austin2021].

The broader Bayesian literature emphasizes the role of priors and model checking. Weakly informative priors, such as Normal(0, 2.5) for coefficients, regularize estimation and reduce variance in small samples [@gelman2008; @vandeschoot2021]. Tutorials using R packages like brms and blavaan illustrate how MCMC enables posterior inference and empirical Bayes analysis [@klauenberg2015].

Beyond standard generalized linear models, Bayesian nonparametric regression flexibly captures nonlinearity and zero inflation common in health data [@richardson2018bnr]. Bayesian Additive Regression Trees (BART) improve variable selection in mixed-type data [@luo2024bartvs], while state-space and dynamic Bayesian models incorporate time-varying biomarkers for longitudinal prediction [@momeni2021covidbayes]. Bayesian model averaging (BMA) further addresses model uncertainty by weighting across multiple specifications [@hoeting1999bma]. 

Together, these approaches demonstrate the versatility and growing importance of Bayesian inference in clinical and epidemiologic modeling.

## Aim 

**Our Aim** is to estimate the association between BMI, age, sex, and race/ethnicity and doctor-diagnosed diabetes among adults (≥20 years) in NHANES 2013–2014, and to evaluate whether a Bayesian approach provides more stable inference than frequentist baselines under missingness and potential separation.

## Data & Preparation

We used data from the **2013-2014 National Health and Nutrition Examination Survey (NHANES)**, conducted by the CDC's National Center for Health Statistics (NCHS) [@nchs2014]. Three datasets were merged for this analysis: 
- `DEMO_H` (demographics)
- `BMX_H` (body measures)
- `DIQ_H` (diabetes questionnaire)

### Population and Variables

The analytic sample included adults aged ≥20 years with complete information on diabetes diagnosis, BMI, age, sex, and race/ethnicity.

Outcome
`DIQ010` - "Has a doctor told you that you have diabetes?" (1 = Yes, 2 = No; 7/9 coded as missing).

Predictors
- `BMXBMI` (Body Mass Index, kg/m²)
- `RIDAGEYR` (Age, years)
- `RIAGENDR` (Sex: Male/Female)
- `RIDRETH1` (Race/Ethnicity: 5 categories)

Survey Design Variables
`WTMEC2YR` (exam weight), `SDMVPSU`, and `SDMVSTRA` were included to preserve NHANES’s complex survey design.

### Data Preparation Workflow

1. Merging and Cleaning
NHANES .XPT files were imported and merged using participant identifiers. Variables were recoded to numeric form where necessary and standardized (e.g., `age_c`, `bmi_c`) to facilitate convergence in regression modeling.

2. Data Validation
Logic checks ensured that all required variables were present and that diabetes outcome values were valid (1 or 2). Missing or nonstandard codes (3, 7, 9) were excluded.

3. Survey Design Specification 
The survey structure was defined using the `survey` package with appropriate weights, strata, and PSU identifiers to ensure nationally representative estimates.

4. Exploratory Visualization
Exploratory visualizations were generated to assess data completeness and distributions:
- Missingness patterns: `plot_intro()` and `plot_missing()` highlighted overall missing data structure.
- Distributions: Preliminary plots examined BMI, age, and diabetes prevalence by demographic groups.

5. Standardization and Storage
Cleaned datasets were saved as `.rds` files (`merged_2013_2014.rds` and `adult_cleaned_2013_2014.rds`) for reproducible downstream analysis.

```{r}
# ---- Load merged data (DEMO_H + BMX_H + DIQ_H) ----
library(tidyverse)
library(survey)

if (!file.exists("data/merged_2013_2014.rds")) {
message("Rebuilding merged_2013_2014.rds via R/data_prep.R ...")
source("R/data_prep.R")  # does: import XPTs, merge, coerce, validate, saveRDS()
}
merged_data <- readRDS("data/merged_2013_2014.rds")

# Verify required columns exist
need_cols <- c("DIQ010","DIQ050","BMXBMI","RIDAGEYR","RIAGENDR",
"RIDRETH1","SDMVPSU","SDMVSTRA","WTMEC2YR")
stopifnot(all(need_cols %in% names(merged_data)))

# ---- Basic Exploration (adults) ----
adult <- merged_data %>%
filter(RIDAGEYR >= 20) %>%
transmute(
SDMVPSU, SDMVSTRA, WTMEC2YR,
diabetes_dx = case_when(
DIQ010 == 1 ~ 1,
DIQ010 == 2 ~ 0,
DIQ010 %in% c(3,7,9) ~ NA_real_,
TRUE ~ NA_real_
),
bmi  = BMXBMI,
age  = RIDAGEYR,
sex  = forcats::fct_recode(factor(RIAGENDR), Male = "1", Female = "2"),
race = forcats::fct_recode(
factor(RIDRETH1),
"Mexican American" = "1",
"Other Hispanic"   = "2",
"NH White"         = "3",
"NH Black"         = "4",
"Other/Multi"      = "5"
),
DIQ050 = DIQ050
) %>%
mutate(
age_c  = as.numeric(scale(age)),
bmi_c  = as.numeric(scale(bmi)),
bmi_cat = cut(
bmi,
breaks = c(-Inf, 18.5, 25, 30, 35, 40, Inf),
labels = c("<18.5","18.5–<25","25–<30","30–<35","35–<40","≥40"),
right = FALSE
),
# exclude gestational diabetes implied by DIQ050==1 for females
diabetes_dx = ifelse(sex == "Female" & !is.na(DIQ050) & DIQ050 == 1, 0, diabetes_dx)
) %>%
mutate(race = forcats::fct_relevel(race, "NH White"))

saveRDS(adult, "data/adult_cleaned_2013_2014.rds")

# ---- Survey Design ----
nhanes_design_adult <- survey::svydesign(
id = ~SDMVPSU,
strata = ~SDMVSTRA,
weights = ~WTMEC2YR,
nest = TRUE,
data = adult
)

# Quick weighted checks
survey::svymean(~age, nhanes_design_adult, na.rm = TRUE)
survey::svymean(~diabetes_dx, nhanes_design_adult, na.rm = TRUE)
```

## Methods

We applied three complementary approaches to estimate the association between BMI, age, sex, and race/ethnicity and doctor-diagnosed diabetes (DIQ010) in the NHANES 2013–2014 adult dataset. Continuous predictors were standardized (mean = 0, SD = 1) to improve model convergence and interpretability. All analyses accounted for NHANES’s complex survey design using weights (`WTMEC2YR`), strata (`SDMVSTRA`), and primary sampling units (`SDMVPSU`).

1. **Frequentist Logistic Regression (MLE):**  
  - Baseline model predicting diabetes from standardized BMI (`bmi_c`), age (`age_c`), sex, and race/ethnicity.
  - Implemented as a survey-weighted logistic regression via the `survey` package in R.
  - Reported population-weighted odds ratios (ORs) with 95% confidence intervals.
  - Limitation: listwise deletion of missing predictors may reduce precision and introduce bias.

2. **Multiple Imputation by Chained Equations (MICE):**  
  - Applied to predictors only (not the diabetes outcome) to address missing data and preserve sample size.
  - Predictive mean matching (`pmm`) was used for continuous variables and polytomous logistic regression (`polyreg`) for categorical predictors.
  - Five imputed datasets were generated and analyzed; results were combined using Rubin’s rules.
  - Survey design variables (`WTMEC2YR`, `SDMVPSU`, `SDMVSTRA`) were included as auxiliary variables but not imputed.
  - Pooled odds ratios with 95% confidence intervals summarized across imputations.

3. **Bayesian Logistic Regression:**  
  - Modeled `DIQ010` ∼ `age_c + bmi_c + sex + race` using the `brms` package.
  - Priors:
    - Coefficients → Normal(0, 2.5) (weakly informative)
    - Intercept → Student-t(3, 0, 10)
  - Sampling used the No-U-Turn Sampler (NUTS) with four chains × 2000 iterations (50% warm-up).
  - `adapt_delta = 0.95` and `max_treedepth = 12` ensured stable convergence.
  - Normalized survey weights (`WTMEC2YR / mean(WTMEC2YR)`) were applied as importance weights to approximate NHANES design effects.
  - Diagnostics included:
    - R-hat < 1.01 and effective sample sizes > 1000 for all parameters.
    - Trace plots inspected for mixing.
    - Posterior predictive checks (`pp_check`) confirmed model fit.
    - Visual inspection of posterior distributions verified that prior influence was minimal.
  - Posterior odds ratios and 95% credible intervals were summarized for interpretability.

## Modeling

```{r}
## Modeling

library(broom)
library(mice)
library(brms)
library(posterior)
library(bayesplot)
library(knitr)

# --- Guardrails for modeling ---
n_outcome <- sum(!is.na(adult$diabetes_dx))
if (n_outcome == 0) stop("Too few non-missing outcomes for modeling. n = 0")

# Ensure factors and >=2 observed levels among complete outcomes
adult <- adult %>%
  dplyr::mutate(
    sex  = if (!is.factor(sex))  factor(sex)  else sex,
    race = if (!is.factor(race)) factor(race) else race
  )

if (nlevels(droplevels(adult$sex[!is.na(adult$diabetes_dx)]))  < 2)
  stop("sex has <2 observed levels after filtering; check data availability.")
if (nlevels(droplevels(adult$race[!is.na(adult$diabetes_dx)])) < 2)
  stop("race has <2 observed levels after filtering; check Data Prep.")

# ------------------------- 1) Survey-weighted complete-case -------------------------
# Build a logical filter on the original adult data (same length as design$data)
keep_cc <- with(
  adult,
  !is.na(diabetes_dx) & !is.na(age_c) & !is.na(bmi_c) &
  !is.na(sex) & !is.na(race)
)

# Subset the survey design using the logical vector (same length as original)
des_cc <- subset(nhanes_design_adult, keep_cc)

# Corresponding complete-case data (optional)
cc <- adult[keep_cc, ] |> droplevels()
cat("\nComplete-case N for survey-weighted model:", nrow(cc), "\n")
print(table(cc$race))

form_cc <- diabetes_dx ~ age_c + bmi_c + sex + race
svy_fit <- survey::svyglm(formula = form_cc, design = des_cc, family = quasibinomial())
summary(svy_fit)

# Survey-weighted OR table (no intercept)
svy_or <- broom::tidy(svy_fit, conf.int = TRUE) %>%
  dplyr::mutate(OR = exp(estimate), LCL = exp(conf.low), UCL = exp(conf.high)) %>%
  dplyr::select(term, OR, LCL, UCL, p.value) %>%
  dplyr::filter(term != "(Intercept)")
knitr::kable(svy_or, caption = "Survey-weighted odds ratios (per 1 SD)")

# ------------------------- 2) Multiple Imputation (predictors only) -------------------------
mi_dat <- adult %>%
  dplyr::select(diabetes_dx, age, bmi, sex, race, WTMEC2YR, SDMVPSU, SDMVSTRA)

meth <- mice::make.method(mi_dat)
pred <- mice::make.predictorMatrix(mi_dat)

# Do not impute outcome
meth["diabetes_dx"] <- ""
pred["diabetes_dx", ] <- 0
pred[,"diabetes_dx"] <- 1

# Imputation methods
meth["age"]  <- "norm"
meth["bmi"]  <- "pmm"
meth["sex"]  <- "polyreg"
meth["race"] <- "polyreg"

# Survey design vars as auxiliaries only
meth[c("WTMEC2YR","SDMVPSU","SDMVSTRA")] <- ""
pred[, c("WTMEC2YR","SDMVPSU","SDMVSTRA")] <- 1

imp <- mice::mice(mi_dat, m = 5, method = meth, predictorMatrix = pred, seed = 123)

fit_mi <- with(imp, {
  age_c <- as.numeric(scale(age))
  bmi_c <- as.numeric(scale(bmi))
  glm(diabetes_dx ~ age_c + bmi_c + sex + race, family = binomial())
})
pool_mi <- pool(fit_mi)
summary(pool_mi)

mi_or <- summary(pool_mi, conf.int = TRUE, exponentiate = TRUE) %>%
  dplyr::rename(
    term = term, OR = estimate, LCL = `2.5 %`, UCL = `97.5 %`, p.value = p.value
  ) %>%
  dplyr::filter(term != "(Intercept)")
knitr::kable(mi_or, caption = "MI pooled odds ratios (per 1 SD)")

# ------------------------- 3) Bayesian Logistic Regression (formula weights) -------------------------
adult_imp1 <- complete(imp, 1) %>%
  dplyr::mutate(
    age_c  = as.numeric(scale(age)),
    bmi_c  = as.numeric(scale(bmi)),
    wt_norm = WTMEC2YR / mean(WTMEC2YR, na.rm = TRUE),
    # ensure factor refs match survey/MICE:
    race = forcats::fct_relevel(race, "NH White"),
    sex  = forcats::fct_relevel(sex,  "Male")
  ) %>%
  dplyr::filter(!is.na(diabetes_dx), !is.na(age_c), !is.na(bmi_c),
                !is.na(sex), !is.na(race)) %>%
  droplevels()

stopifnot(all(is.finite(adult_imp1$wt_norm)))

priors <- c(
  set_prior("normal(0, 2.5)", class = "b"),
  set_prior("student_t(3, 0, 10)", class = "Intercept")
)

bayes_fit <- brm(
  formula = diabetes_dx | weights(wt_norm) ~ age_c + bmi_c + sex + race,
  data    = adult_imp1,
  family  = bernoulli(link = "logit"),
  prior   = priors,
  chains  = 4, iter = 2000, seed = 123,
  control = list(adapt_delta = 0.95),
  refresh = 0   # quiet Stan output
)

summary(bayes_fit)

# Posterior ORs (drop intercept, clean labels)
bayes_or <- posterior_summary(bayes_fit, pars = "^b_") %>%
  as.data.frame() %>%
  tibble::rownames_to_column("raw") %>%
  dplyr::mutate(
    term = gsub("^b_", "", raw),
    term = gsub("race", "race:", term),
    term = gsub("sex",  "sex:",  term),
    term = gsub("OtherDMulti", "Other/Multi", term),
    term = gsub("OtherHispanic", "Other Hispanic", term),
    OR   = exp(Estimate),
    LCL  = exp(Q2.5),
    UCL  = exp(Q97.5)
  ) %>%
  dplyr::select(term, OR, LCL, UCL) %>%
  dplyr::filter(term != "Intercept")

knitr::kable(
  bayes_or %>%
    dplyr::mutate(dplyr::across(c(OR,LCL,UCL), ~round(.x, 2))),
  digits = 2,
  caption = "Bayesian posterior odds ratios (95% CrI) — reference: NH White (race), Male (sex)"
)

# ------------------------- Save artifacts (optional) -------------------------
if (!dir.exists("outputs")) dir.create("outputs", recursive = TRUE)
saveRDS(svy_fit,   "outputs/svy_fit.rds")
saveRDS(pool_mi,   "outputs/pool_mi.rds")
saveRDS(bayes_fit, "outputs/bayes_fit.rds")
saveRDS(svy_or,    "outputs/survey_OR_table.rds")
saveRDS(mi_or,     "outputs/mi_OR_table.rds")
saveRDS(bayes_or,  "outputs/bayes_OR_table.rds")
```

## Results  

```{r}
# ---- Build compact results table (BMI & Age only) ----
library(dplyr); library(tidyr); library(knitr); library(stringr)

# pretty "OR (LCL–UCL)" string
fmt_or <- function(or, lcl, ucl, digits = 2) {
  paste0(
    formatC(or,  format = "f", digits = digits), " (",
    formatC(lcl, format = "f", digits = digits), "–",
    formatC(ucl, format = "f", digits = digits), ")"
  )
}

# guardrails: require these to exist from Modeling
stopifnot(exists("svy_or"), exists("mi_or"), exists("bayes_or"))
for (nm in c("svy_or","mi_or","bayes_or")) {
  if (!all(c("term","OR","LCL","UCL") %in% names(get(nm)))) {
    stop(nm, " must have columns: term, OR, LCL, UCL")
  }
}

svy_tbl   <- svy_or   %>% mutate(Model = "Survey-weighted MLE")
mi_tbl    <- mi_or    %>% mutate(Model = "MICE pooled")
bayes_tbl <- bayes_or %>% mutate(Model = "Bayesian")

all_tbl <- bind_rows(svy_tbl, mi_tbl, bayes_tbl) %>%
  mutate(term = case_when(
    str_detect(term, "bmi_c|\\bBMI\\b") ~ "BMI (per 1 SD)",
    str_detect(term, "age_c|\\bAge\\b") ~ "Age (per 1 SD)",
    TRUE ~ term
  )) %>%
  filter(term %in% c("BMI (per 1 SD)", "Age (per 1 SD)")) %>%
  mutate(OR_CI = fmt_or(OR, LCL, UCL, digits = 2)) %>%
  select(Model, term, OR_CI) %>%
  arrange(
    factor(Model, levels = c("Survey-weighted MLE","MICE pooled","Bayesian")),
    factor(term,  levels = c("BMI (per 1 SD)","Age (per 1 SD)"))
  )

res_wide <- all_tbl %>%
  pivot_wider(names_from = term, values_from = OR_CI) %>%
  rename(
    `BMI (per 1 SD) OR (95% CI)` = `BMI (per 1 SD)`,
    `Age (per 1 SD) OR (95% CI)` = `Age (per 1 SD)`
  )

kable(
  res_wide,
  align = c("l","c","c"),
  caption = "Odds ratios (per 1 SD) with 95% CIs across models"
)
```

Higher BMI and age were both significantly associated with increased odds of doctor-diagnosed diabetes across all models.  

Results were consistent between frequentist and Bayesian frameworks, with Bayesian credible intervals showing comparable precision.

### Comparative Interpretation

Across all modeling strategies—survey-weighted MLE, multiple imputation (MICE), and Bayesian logistic regression—the associations between age, BMI, sex, and race/ethnicity with doctor-diagnosed diabetes were consistent in magnitude and direction.  

- **Effect stability:** Point estimates from the Bayesian model closely matched those from the frequentist models, suggesting that prior regularization did not distort inference but instead stabilized estimates under modest missingness.  
- **Uncertainty quantification:** Bayesian credible intervals were slightly narrower yet fully overlapped with frequentist confidence intervals, indicating similar inferential precision with improved interpretability.  
- **Design considerations:** While the survey-weighted MLE incorporated NHANES’s complex sampling design directly, the Bayesian model used normalized sampling weights as importance weights—approximating design effects rather than modeling them fully. Therefore, Bayesian results are best interpreted as model-based rather than population-weighted estimates.  

Overall, the Bayesian approach yielded inference that was comparably accurate, more transparent about uncertainty, and less sensitive to small-sample variability.

### Discussion and Conclusion

This analysis examined whether Bayesian logistic regression offers more stable and interpretable inference than classical logistic regression when modeling diabetes risk factors using NHANES 2013–2014 data. All methods—frequentist, imputed, and Bayesian—identified age and BMI as the strongest predictors of doctor-diagnosed diabetes, with higher odds among older adults and those with higher BMI. Females consistently showed lower odds of diabetes than males, while Mexican American, non-Hispanic Black, and multiracial adults exhibited elevated odds compared to non-Hispanic Whites. These sex-specific and racial disparities align with well-documented patterns in population-level diabetes research, where differences in lifestyle, genetics, and access to healthcare contribute to unequal disease burden across groups.

The Bayesian approach provided several advantages. By integrating weakly informative priors, it produced regularized parameter estimates that avoided instability under missing data or quasi-separation. Its posterior distributions offered richer insight into uncertainty than single-point frequentist estimates. In contrast, traditional MLE and even multiple imputation can yield biased or overly confident estimates in small or incomplete samples.  

Although the Bayesian model approximated survey weighting rather than fully modeling NHANES’s complex design, the resulting estimates aligned closely with design-based frequentist results, supporting its robustness. The high effective sample sizes and R̂ ≈ 1.00 across parameters confirmed excellent model convergence.  

**In conclusion,** Bayesian logistic regression provided inference that was statistically consistent, computationally stable, and interpretable—achieving the aim of this project. Its flexibility and transparency make it a valuable complement to classical regression in epidemiologic research, particularly when data are incomplete or model assumptions are strained. Future work could extend this approach to hierarchical NHANES cycles or include biomarkers to assess nonlinear effects of metabolic risk factors.

Future work could (i) compare linear-term models with nonlinear BART-based classifiers and permutation/backward selection for variable importance [@luo2024bartvs], (ii) evaluate Bayesian model averaging to reflect model uncertainty across alternative covariate sets [@hoeting1999bma], and (iii) extend to dynamic Bayesian models that update diabetes risk as longitudinal biomarkers accrue [@momeni2021covidbayes].

