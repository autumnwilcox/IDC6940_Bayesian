---
title: "Bayesian Logistic Regression for Predicting Diabetes Risk Using NHANES 2013–2014 Data"
subtitle: "A Capstone Project on Bayesian Applications in Epidemiologic Modeling"
author:
  - "Namita Mishra"
  - "Autumn Wilcox"
  - "Ecil Teodoro"
advisor: "Dr. Ashraf Cohen"
date: '`r Sys.Date()`'
course: Capstone Projects in Data Science

format:
  html:
    code-fold: true
    toc: true

bibliography: references.bib
reference-section-title: "References"
link-citations: true
self-contained: true

execute:
  warning: false
  message: false

editor:
  markdown:
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} (Edit `slides.qmd`.)

## Group Project Workflow and Contributions

This project was developed collaboratively as part of the Capstone Projects in Data Science course under the guidance of Dr. Ashraf Cohen. The team followed an iterative workflow encompassing data preparation, model development, validation, and documentation using GitHub for version control and collaborative editing.

- Autumn Wilcox – Contributed to analytic coding, content drafting, and structured the overall project workflow. Led documentation efforts and coordinated GitHub updates.
- Namita Mishra – Developed the initial project plan, conducted Bayesian model implementation, and integrated analytic code with visual diagnostics and posterior checks.
- Ecil Teodoro – Drafted sections of the Introduction and assisted in literature review and editing for clarity and cohesion.

## Introduction
Diabetes mellitus (DM) remains a major public health challenge, and identifying key risk factors—such as obesity, age, sex, and race/ethnicity—is essential for prevention and targeted intervention. Logistic regression is widely used to estimate associations between such factors and binary outcomes like diabetes diagnosis. However, classical maximum likelihood estimation (MLE) can produce unstable estimates in the presence of missing data, quasi-separation, or small samples. Bayesian logistic regression offers a robust alternative by integrating prior information, regularizing estimates, and quantifying uncertainty more transparently than frequentist approaches.

In this project, we apply Bayesian logistic regression to the 2013–2014 National Health and Nutrition Examination Survey (NHANES) dataset to examine the association between demographic and anthropometric factors and doctor-diagnosed diabetes. Our objective is to evaluate whether Bayesian inference provides more stable and interpretable estimates than frequentist baselines when data complexity or separation challenges arise.

Bayesian hierarchical models, implemented via Markov Chain Monte Carlo (MCMC), have been successfully applied in predicting patient health status across diseases such as pneumonia, prostate cancer, and mental disorders [@zeger2020]. By representing predictive uncertainty alongside point estimates, Bayesian inference offers a practical advantage in epidemiologic modeling where decisions hinge on probabilistic thresholds. Beyond stability, Bayesian methods support model checking, variable selection, and uncertainty quantification under missingness or imputation frameworks [@baldwin2017; @kruschke2017].

Recent work has expanded Bayesian applications to disease diagnostics and health risk modeling. For instance, Bayesian approaches have been used to evaluate NHANES diagnostic data [@chatzimichail2023], to model cardiovascular and metabolic risk [@liu2013], and to integrate multiple data modalities such as imaging and laboratory measures [@abdullah2022bdlhealth]. Moreover, multiple imputation combined with Bayesian modeling generates robust estimates when data are missing at random (MAR) or not at random (MNAR) [@austin2021].

The broader Bayesian literature emphasizes the role of priors and model checking. Weakly informative priors, such as Normal(0, 2.5) for coefficients, regularize estimation and reduce variance in small samples [@gelman2008; @vandeschoot2021]. Tutorials using R packages like brms and blavaan illustrate how MCMC enables posterior inference and empirical Bayes analysis [@klauenberg2015].

Beyond standard generalized linear models, Bayesian nonparametric regression flexibly captures nonlinearity and zero inflation common in health data [@richardson2018bnr]. Bayesian Additive Regression Trees (BART) improve variable selection in mixed-type data [@luo2024bartvs], while state-space and dynamic Bayesian models incorporate time-varying biomarkers for longitudinal prediction [@momeni2021covidbayes]. Bayesian model averaging (BMA) further addresses model uncertainty by weighting across multiple specifications [@hoeting1999bma]. 

Together, these approaches demonstrate the versatility and growing importance of Bayesian inference in clinical and epidemiologic modeling.

## Aim 

**Our Aim** is to estimate the association between BMI, age, sex, and race/ethnicity and doctor-diagnosed diabetes among adults (≥20 years) in NHANES 2013–2014, and to evaluate whether a Bayesian approach provides more stable inference than frequentist baselines under missingness and potential separation.

## Data & Preparation

We used data from the **2013-2014 National Health and Nutrition Examination Survey (NHANES)**, conducted by the CDC's National Center for Health Statistics (NCHS) [@nchs2014]. Three datasets were merged for this analysis: 
- `DEMO_H` (demographics)
- `BMX_H` (body measures)
- `DIQ_H` (diabetes questionnaire)

### Population and Variables

The analytic sample included adults aged ≥20 years with complete information on diabetes diagnosis, BMI, age, sex, and race/ethnicity.

Outcome
`DIQ010` - "Has a doctor told you that you have diabetes?" (1 = Yes, 2 = No; 7/9 coded as missing).

Predictors
- `BMXBMI` (Body Mass Index, kg/m²)
- `RIDAGEYR` (Age, years)
- `RIAGENDR` (Sex: Male/Female)
- `RIDRETH1` (Race/Ethnicity: 5 categories)

Survey Design Variables
`WTMEC2YR` (exam weight), `SDMVPSU`, and `SDMVSTRA` were included to preserve NHANES’s complex survey design.

### Data Preparation Workflow

1. Merging and Cleaning
NHANES .XPT files were imported and merged using participant identifiers. Variables were recoded to numeric form where necessary and standardized (e.g., `age_c`, `bmi_c`) to facilitate convergence in regression modeling.

2. Data Validation
Logic checks ensured that all required variables were present and that diabetes outcome values were valid (1 or 2). Missing or nonstandard codes (3, 7, 9) were excluded.

3. Survey Design Specification 
The survey structure was defined using the `survey` package with appropriate weights, strata, and PSU identifiers to ensure nationally representative estimates.

4. Exploratory Visualization
Exploratory visualizations were generated to assess data completeness and distributions:
- Missingness patterns: `plot_intro()` and `plot_missing()` highlighted overall missing data structure.
- Distributions: Preliminary plots examined BMI, age, and diabetes prevalence by demographic groups.

5. Standardization and Storage
Cleaned datasets were saved as `.rds` files (`merged_2013_2014.rds` and `adult_cleaned_2013_2014.rds`) for reproducible downstream analysis.

```{r}
# ---- Load merged data (DEMO_H + BMX_H + DIQ_H) ----
library(tidyverse)
library(survey)
library(forcats)

if (!file.exists("data/merged_2013_2014.rds")) {
message("Rebuilding merged_2013_2014.rds via R/data_prep.R ...")
source("R/data_prep.R")  # does: import XPTs, merge, coerce, validate, saveRDS()
}
merged_data <- readRDS("data/merged_2013_2014.rds")

# Verify required columns exist
need_cols <- c("DIQ010","DIQ050","BMXBMI","RIDAGEYR","RIAGENDR",
"RIDRETH1","SDMVPSU","SDMVSTRA","WTMEC2YR")
stopifnot(all(need_cols %in% names(merged_data)))

# ---- Basic Exploration (adults) ----
adult <- merged_data %>%
filter(RIDAGEYR >= 20) %>%
transmute(
SDMVPSU, SDMVSTRA, WTMEC2YR,
diabetes_dx = case_when(
DIQ010 == 1 ~ 1,
DIQ010 == 2 ~ 0,
DIQ010 %in% c(3,7,9) ~ NA_real_,
TRUE ~ NA_real_
),
bmi  = BMXBMI,
age  = RIDAGEYR,
sex  = forcats::fct_recode(factor(RIAGENDR), Male = "1", Female = "2"),
race = forcats::fct_recode(
factor(RIDRETH1),
"Mexican American" = "1",
"Other Hispanic"   = "2",
"NH White"         = "3",
"NH Black"         = "4",
"Other/Multi"      = "5"
),
DIQ050 = DIQ050
) %>%
mutate(
age_c  = as.numeric(scale(age)),
bmi_c  = as.numeric(scale(bmi)),
bmi_cat = cut(
bmi,
breaks = c(-Inf, 18.5, 25, 30, 35, 40, Inf),
labels = c("<18.5","18.5–<25","25–<30","30–<35","35–<40","≥40"),
right = FALSE
),
# exclude gestational diabetes implied by DIQ050==1 for females
diabetes_dx = ifelse(sex == "Female" & !is.na(DIQ050) & DIQ050 == 1, 0, diabetes_dx)
) %>%
mutate(race = forcats::fct_relevel(race, "NH White"))

saveRDS(adult, "data/adult_cleaned_2013_2014.rds")

# ---- Survey Design ----
nhanes_design_adult <- survey::svydesign(
id = ~SDMVPSU,
strata = ~SDMVSTRA,
weights = ~WTMEC2YR,
nest = TRUE,
data = adult
)

# Quick weighted checks
survey::svymean(~age, nhanes_design_adult, na.rm = TRUE)
survey::svymean(~diabetes_dx, nhanes_design_adult, na.rm = TRUE)
```

## Methods

The general logistic regression model estimated the probability of doctor-diagnosed diabetes (`DIQ010`) as a function of demographic and anthropometric predictors. The model is expressed as:

$$
\text{logit}(P(Y_i = 1)) = \beta_0 + \beta_1(\text{BMI}_i) + \beta_2(\text{Age}_i) + \beta_3(\text{Sex}_i) + \sum_{k=1}^{4}\beta_{3+k}(\text{Race}_{ik})
$$

where \( Y_i = 1 \) indicates a positive diabetes diagnosis for individual \( i \).  
- \( \beta_0 \) is the intercept.  
- \( \beta_1, \beta_2, \beta_3, \ldots \) are regression coefficients representing the log-odds change in diabetes risk associated with each predictor.  

Continuous predictors (BMI, age) were standardized (mean = 0, SD = 1) prior to model estimation.  
All analyses accounted for NHANES’s complex survey design using weights (`WTMEC2YR`), strata (`SDMVSTRA`), and primary sampling units (`SDMVPSU`).  

We implemented three complementary modeling strategies to evaluate these associations:

1. **Frequentist Logistic Regression (MLE):**  
  - Baseline model predicting diabetes from standardized BMI (`bmi_c`), age (`age_c`), sex, and race/ethnicity.
  - Implemented as a survey-weighted logistic regression via the `survey` package in R.
  - Reported population-weighted odds ratios (ORs) with 95% confidence intervals.
  - Limitation: listwise deletion of missing predictors may reduce precision and introduce bias.

2. **Multiple Imputation by Chained Equations (MICE):**  
  - Applied to predictors only (not the diabetes outcome) to address missing data and preserve sample size.
  - Predictive mean matching (`pmm`) was used for continuous variables and polytomous logistic regression (`polyreg`) for categorical predictors.
  - Five imputed datasets were generated and analyzed; results were combined using Rubin’s rules.
  - Survey design variables (`WTMEC2YR`, `SDMVPSU`, `SDMVSTRA`) were included as auxiliary variables but not imputed.
  - Pooled odds ratios with 95% confidence intervals summarized across imputations.

3. **Bayesian Logistic Regression:**  
  - Modeled `DIQ010` ∼ `age_c + bmi_c + sex + race` using the `brms` package.
  - Priors:
    - Coefficients → Normal(0, 2.5) (weakly informative)
    - Intercept → Student-t(3, 0, 10)
  - Sampling used the No-U-Turn Sampler (NUTS) with four chains × 2000 iterations (50% warm-up).
  - `adapt_delta = 0.95` and `max_treedepth = 12` ensured stable convergence.
  - Normalized survey weights (`WTMEC2YR / mean(WTMEC2YR)`) were applied as importance weights to approximate NHANES design effects.
  - Diagnostics included:
    - R-hat < 1.01 and effective sample sizes > 1000 for all parameters.
    - Trace plots inspected for mixing.
    - Posterior predictive checks (`pp_check`) confirmed model fit.
    - Visual inspection of posterior distributions verified that prior influence was minimal.
  - Posterior odds ratios and 95% credible intervals were summarized for interpretability.

### Software and Methods Note

All analyses were conducted in R (version 4.3.2) using RStudio within a reproducible Quarto workflow.
The following libraries supported data management, modeling, and visualization:
- `tidyverse` – data wrangling, transformation, and plotting
- `nhanesA` – direct import of NHANES public datasets
- `survey` – complex survey design specification and weighted analysis
- `mice` – multiple imputation of missing predictor data
- `brms` and `rstan` – Bayesian regression modeling and posterior simulation
- `bayesplot` and `ggplot2` – model diagnostics and posterior visualization
- `knitr` and `kableExtra` – formatted tables for model output

All code was executed using reproducible R scripts housed in the project’s GitHub repository (`R/data_prep.R`, `R/modeling.R`), with outputs rendered dynamically via Quarto (`index.qmd`).

## Modeling

```{r}
library(broom)
library(mice)
library(brms)
library(posterior)
library(bayesplot)
library(knitr)

# --- Guardrails for modeling ---
n_outcome <- sum(!is.na(adult$diabetes_dx))
if (n_outcome == 0) stop("Too few non-missing outcomes for modeling. n = 0")

# Ensure factors and >=2 observed levels among complete outcomes
adult <- adult %>%
  dplyr::mutate(
    sex  = if (!is.factor(sex))  factor(sex)  else sex,
    race = if (!is.factor(race)) factor(race) else race
  )

if (nlevels(droplevels(adult$sex[!is.na(adult$diabetes_dx)]))  < 2)
  stop("sex has <2 observed levels after filtering; check data availability.")
if (nlevels(droplevels(adult$race[!is.na(adult$diabetes_dx)])) < 2)
  stop("race has <2 observed levels after filtering; check Data Prep.")

# ------------------------- 1) Survey-weighted complete-case -------------------------
# Build a logical filter on the original adult data (same length as design$data)
keep_cc <- with(
  adult,
  !is.na(diabetes_dx) & !is.na(age_c) & !is.na(bmi_c) &
  !is.na(sex) & !is.na(race)
)

# Subset the survey design using the logical vector (same length as original)
des_cc <- subset(nhanes_design_adult, keep_cc)

# Corresponding complete-case data (optional)
cc <- adult[keep_cc, ] |> droplevels()
cat("\nComplete-case N for survey-weighted model:", nrow(cc), "\n")
print(table(cc$race))

form_cc <- diabetes_dx ~ age_c + bmi_c + sex + race
svy_fit <- survey::svyglm(formula = form_cc, design = des_cc, family = quasibinomial())
summary(svy_fit)

# Survey-weighted OR table (no intercept)
svy_or <- broom::tidy(svy_fit, conf.int = TRUE) %>%
  dplyr::mutate(OR = exp(estimate), LCL = exp(conf.low), UCL = exp(conf.high)) %>%
  dplyr::select(term, OR, LCL, UCL, p.value) %>%
  dplyr::filter(term != "(Intercept)")
knitr::kable(svy_or, caption = "Survey-weighted odds ratios (per 1 SD)")

# ------------------------- 2) Multiple Imputation (predictors only) -------------------------
mi_dat <- adult %>%
  dplyr::select(diabetes_dx, age, bmi, sex, race, WTMEC2YR, SDMVPSU, SDMVSTRA)

meth <- mice::make.method(mi_dat)
pred <- mice::make.predictorMatrix(mi_dat)

# Do not impute outcome
meth["diabetes_dx"] <- ""
pred["diabetes_dx", ] <- 0
pred[,"diabetes_dx"] <- 1

# Imputation methods
meth["age"]  <- "norm"
meth["bmi"]  <- "pmm"
meth["sex"]  <- "polyreg"
meth["race"] <- "polyreg"

# Survey design vars as auxiliaries only
meth[c("WTMEC2YR","SDMVPSU","SDMVSTRA")] <- ""
pred[, c("WTMEC2YR","SDMVPSU","SDMVSTRA")] <- 1

imp <- mice::mice(mi_dat, m = 5, method = meth, predictorMatrix = pred, seed = 123)

fit_mi <- with(imp, {
  age_c <- as.numeric(scale(age))
  bmi_c <- as.numeric(scale(bmi))
  glm(diabetes_dx ~ age_c + bmi_c + sex + race, family = binomial())
})
pool_mi <- pool(fit_mi)
summary(pool_mi)

mi_or <- summary(pool_mi, conf.int = TRUE, exponentiate = TRUE) %>%
  dplyr::rename(
    term = term, OR = estimate, LCL = `2.5 %`, UCL = `97.5 %`, p.value = p.value
  ) %>%
  dplyr::filter(term != "(Intercept)")
knitr::kable(mi_or, caption = "MI pooled odds ratios (per 1 SD)")

# ------------------------- 3) Bayesian Logistic Regression (formula weights) -------------------------
adult_imp1 <- complete(imp, 1) %>%
  dplyr::mutate(
    age_c  = as.numeric(scale(age)),
    bmi_c  = as.numeric(scale(bmi)),
    wt_norm = WTMEC2YR / mean(WTMEC2YR, na.rm = TRUE),
    # ensure factor refs match survey/MICE:
    race = forcats::fct_relevel(race, "NH White"),
    sex  = forcats::fct_relevel(sex,  "Male")
  ) %>%
  dplyr::filter(!is.na(diabetes_dx), !is.na(age_c), !is.na(bmi_c),
                !is.na(sex), !is.na(race)) %>%
  droplevels()

stopifnot(all(is.finite(adult_imp1$wt_norm)))

priors <- c(
  set_prior("normal(0, 2.5)", class = "b"),
  set_prior("student_t(3, 0, 10)", class = "Intercept")
)

bayes_fit <- brm(
  formula = diabetes_dx | weights(wt_norm) ~ age_c + bmi_c + sex + race,
  data    = adult_imp1,
  family  = bernoulli(link = "logit"),
  prior   = priors,
  chains  = 4, iter = 2000, seed = 123,
  control = list(adapt_delta = 0.95),
  refresh = 0   # quiet Stan output
)

summary(bayes_fit)

# Posterior ORs (drop intercept, clean labels)
bayes_or <- posterior_summary(bayes_fit, pars = "^b_") %>%
  as.data.frame() %>%
  tibble::rownames_to_column("raw") %>%
  dplyr::mutate(
    term = gsub("^b_", "", raw),
    term = gsub("race", "race:", term),
    term = gsub("sex",  "sex:",  term),
    term = gsub("OtherDMulti", "Other/Multi", term),
    term = gsub("OtherHispanic", "Other Hispanic", term),
    OR   = exp(Estimate),
    LCL  = exp(Q2.5),
    UCL  = exp(Q97.5)
  ) %>%
  dplyr::select(term, OR, LCL, UCL) %>%
  dplyr::filter(term != "Intercept")

knitr::kable(
  bayes_or %>%
    dplyr::mutate(dplyr::across(c(OR,LCL,UCL), ~round(.x, 2))),
  digits = 2,
  caption = "Bayesian posterior odds ratios (95% CrI) — reference: NH White (race), Male (sex)"
)

# ------------------------- Save artifacts (optional) -------------------------
if (!dir.exists("outputs")) dir.create("outputs", recursive = TRUE)
saveRDS(svy_fit,   "outputs/svy_fit.rds")
saveRDS(pool_mi,   "outputs/pool_mi.rds")
saveRDS(bayes_fit, "outputs/bayes_fit.rds")
saveRDS(svy_or,    "outputs/survey_OR_table.rds")
saveRDS(mi_or,     "outputs/mi_OR_table.rds")
saveRDS(bayes_or,  "outputs/bayes_OR_table.rds")
```

### Bayesian Diagnostics

Model convergence and fit were assessed using standard Bayesian diagnostics:

- **Trace plots** confirmed good mixing and stationarity across all four chains.  
- **Autocorrelation plots** verified that posterior draws were sufficiently independent.  
- **R-hat (Ȓ)** values were < 1.01 for all parameters, indicating proper convergence.  
- **Effective sample sizes (ESS)** exceeded 1000, ensuring reliable posterior estimation.  
- **Posterior predictive checks (`pp_check`)** demonstrated that simulated outcomes closely matched the observed distribution of diabetes diagnoses.  
- **Bayesian R²** from `brms` summarized the proportion of variance explained by the model.

Together, these diagnostics indicated that the Bayesian logistic regression model converged appropriately, achieved stable sampling, and provided a well-calibrated fit to the NHANES 2013–2014 data.

## Results  

**Key Findings**
- Age and BMI are positively associated with doctor-diagnosed diabetes across MLE, MICE, and Bayesian models.
- Female sex shows lower odds vs. male in all models.
- Race/ethnicity: Mexican American, NH Black, and Other/Multi have elevated odds vs. NH White; Other Hispanic is positive but sometimes less precise.
- Agreement across methods: Effect sizes are directionally and numerically consistent (robust to listwise deletion, imputation, and priors).

```{r}
# ---- Build compact results table (BMI & Age only) ----
library(dplyr) 
library(tidyr)
library(knitr)
library(stringr)

# pretty "OR (LCL–UCL)" string
fmt_or <- function(or, lcl, ucl, digits = 2) {
paste0(
formatC(or,  format = "f", digits = digits), " (",
formatC(lcl, format = "f", digits = digits), "–",
formatC(ucl, format = "f", digits = digits), ")"
)
}

# guardrails: require these to exist from Modeling
stopifnot(exists("svy_or"), exists("mi_or"), exists("bayes_or"))
for (nm in c("svy_or","mi_or","bayes_or")) {
if (!all(c("term","OR","LCL","UCL") %in% names(get(nm)))) {
stop(nm, " must have columns: term, OR, LCL, UCL")
}
}

svy_tbl   <- svy_or   %>% mutate(Model = "Survey-weighted MLE")
mi_tbl    <- mi_or    %>% mutate(Model = "MICE pooled")
bayes_tbl <- bayes_or %>% mutate(Model = "Bayesian")

all_tbl <- bind_rows(svy_tbl, mi_tbl, bayes_tbl) %>%
mutate(term = case_when(
str_detect(term, "bmi_c|\\bBMI\\b") ~ "BMI (per 1 SD)",
str_detect(term, "age_c|\\bAge\\b") ~ "Age (per 1 SD)",
TRUE ~ term
)) %>%
filter(term %in% c("BMI (per 1 SD)", "Age (per 1 SD)")) %>%
mutate(OR_CI = fmt_or(OR, LCL, UCL, digits = 2)) %>%
select(Model, term, OR_CI) %>%
arrange(
factor(Model, levels = c("Survey-weighted MLE","MICE pooled","Bayesian")),
factor(term,  levels = c("BMI (per 1 SD)","Age (per 1 SD)"))
)

res_wide <- all_tbl %>%
pivot_wider(names_from = term, values_from = OR_CI) %>%
rename(
`BMI (per 1 SD) OR (95% CI)` = `BMI (per 1 SD)`,
`Age (per 1 SD) OR (95% CI)` = `Age (per 1 SD)`
)

kable(
res_wide,
align = c("l","c","c"),
caption = "Odds ratios (per 1 SD) with 95% CIs across models"
)
```

Higher BMI and age were both significantly associated with increased odds of doctor-diagnosed diabetes across all models. Results were consistent between frequentist and Bayesian frameworks, with Bayesian credible intervals showing comparable precision.

### Comparative Interpretation

Magnitude & direction:
- Age (per 1 SD): strong positive association across models.
- BMI (per 1 SD): positive association; somewhat smaller than age but robust.
- Sex (Female vs Male): OR < 1 across methods.
- Race/ethnicity: Mexican American, NH Black, Other/Multi > 1 vs NH White; Other Hispanic positive with wider intervals at times.

Across methods (MLE, MICE, Bayesian):
- Consistency in signs and magnitudes indicates conclusions are not sensitive to listwise deletion, multiple imputation, or weakly informative priors.
- Precision: Bayesian CrIs are similar to frequentist CIs, sometimes slightly narrower due to regularization that stabilizes estimates without overwhelming the likelihood.

Design vs model-based:
- Survey-weighted MLE targets population-representative effects (weights/strata/PSU).
- Bayesian used normalized weights as importance weights—an approximation that yielded similar substantive conclusions while enabling full posterior inference.

### Model Fit and Uncertainty 
```{r}
# Bayes R^2 (summary)
library(brms)
r2 <- bayes_R2(bayes_fit, summary = TRUE)
knitr::kable(as.data.frame(r2), caption = "Bayesian R² summary (mean and credible interval)")
```

- Convergence: Ȓ < 1.01 and large ESS (see Bayesian Diagnostics) indicate reliable sampling.
- Calibration: Posterior predictive checks (bars/stat/scatter) showed close agreement between simulated and observed outcomes.
- Explained variance: Bayes R² indicates the model captures a meaningful portion of outcome variability for a compact covariate set.

## Discussion and Conclusion

This analysis assessed whether Bayesian logistic regression provides stable, interpretable inference relative to classical approaches for diabetes risk in NHANES 2013–2014. All methods—MLE, imputed, and Bayesian—identified age and BMI as dominant predictors, with female sex protective and several race/ethnicity contrasts elevated vs NH White. The Bayesian approach offered full posterior uncertainty and modest regularization, aligning closely with survey-weighted estimates while remaining computationally stable.

In conclusion, the convergent evidence across methods supports a robust finding: age and BMI are key risk factors for doctor-diagnosed diabetes in this population. Bayesian diagnostics and Bayes R² further support that the model is well-calibrated and decision-relevant. Future work could expand to hierarchical NHANES cycles, incorporate laboratory biomarkers, compare with nonlinear learners (e.g., BART), and apply Bayesian model averaging to reflect specification uncertainty.

### Translational Perspective
While our primary focus was on methodological comparison, these findings also carry implications for precision public health. Bayesian frameworks enable individualized prediction and uncertainty quantification—tools that could support risk stratification and targeted intervention in population health. For example, model outputs can be used to estimate the posterior probability of diabetes for a specific patient profile or identify the BMI threshold at which that probability exceeds a chosen risk level.

**Example: predict diabetes probability for a single hypothetical adult**
```{r}
new_patient <- tibble(
age_c = 0.5,       # half SD above mean age
bmi_c = 1.0,       # one SD above mean BMI
sex   = factor("Male", levels = levels(adult$sex)),
race  = factor("NH White", levels = levels(adult$race))
)

pred <- posterior_epred(bayes_fit, newdata = new_patient)
quantile(colMeans(pred), probs = c(0.025, 0.5, 0.975))
```

**Example: inverse prediction – BMI at 50% predicted probability**
```{r}
# (approximate using grid search)
bmi_grid <- seq(-3, 3, 0.1)
grid_df <- tibble(
age_c = 0,
bmi_c = bmi_grid,
sex   = factor("Male", levels = levels(adult$sex)),
race  = factor("NH White", levels = levels(adult$race))
)
pred_grid <- posterior_epred(bayes_fit, newdata = grid_df)
mean_prob <- colMeans(pred_grid)
approx(x = mean_prob, y = bmi_grid, xout = 0.5)$y
```

These examples illustrate how Bayesian inference can bridge population-level modeling and individualized prediction—key to translating epidemiologic data into actionable prevention strategies.

## Limitations

Several limitations should be acknowledged.

First, while NHANES provides a nationally representative sample, the cross-sectional design precludes causal inference between predictors and diabetes outcomes.

Second, the Bayesian logistic regression model approximated survey weighting rather than fully incorporating NHANES’s complex design structure (PSUs and strata) into the likelihood, meaning the results are model-based rather than fully population-weighted.

Third, self-reported diabetes diagnosis (`DIQ010`) may introduce recall bias or misclassification error.
Fourth, although multiple imputation was used to mitigate missingness, this assumes data are missing at random, which may not always hold.

Finally, the analysis focused on a limited set of demographic and anthropometric predictors; unmeasured confounders such as diet, physical activity, or socioeconomic status could influence observed associations.

Despite these limitations, the findings provide robust and interpretable estimates of diabetes risk factors and demonstrate the stability of Bayesian inference in epidemiologic modeling.

## Visualizations 
```{r}
suppressPackageStartupMessages({
library(ggplot2)
library(dplyr)
library(DataExplorer)
library(bayesplot)
library(brms)
library(survey)
library(viridis)
})
theme_set(theme_minimal(base_size = 13))
color_scheme_set("viridis")
```

1. Data Quality & Missingness
```{r}
plot_intro(merged_data)
plot_missing(merged_data)
```

2. Exploratory Distributions
```{r}
# BMI distribution by diabetes status (0 = No, 1 = Yes)
ggplot(adult, aes(x = bmi, fill = factor(diabetes_dx))) +
geom_density(alpha = 0.6) +
scale_fill_viridis_d(name = "Diabetes (1 = Yes, 0 = No)") +
labs(
title = "BMI Distribution by Diabetes Status",
x = "Body Mass Index (BMI)",
y = "Density"
)

# Age distribution by diabetes status
ggplot(adult, aes(x = age, fill = factor(diabetes_dx))) +
geom_histogram(position = "identity", alpha = 0.5, bins = 40) +
scale_fill_viridis_d(name = "Diabetes (1 = Yes, 0 = No)") +
labs(
title = "Age Distribution by Diabetes Status",
x = "Age (years)",
y = "Count"
)
```

3. Predicted Probability vs BMI (Bayesian)
```{r}
pp_df <- tibble(
bmi_c = seq(min(adult$bmi_c, na.rm = TRUE), max(adult$bmi_c, na.rm = TRUE), length.out = 120),
age_c = mean(adult$age_c, na.rm = TRUE),
sex   = factor("Male", levels = levels(adult$sex)),
race  = factor("NH White", levels = levels(adult$race))
)

# Posterior expected probabilities
pp_pred <- posterior_epred(bayes_fit, newdata = pp_df)
pp_df <- pp_df %>%
mutate(
pred  = apply(pp_pred, 2, mean),
lower = apply(pp_pred, 2, quantile, 0.025),
upper = apply(pp_pred, 2, quantile, 0.975)
)

ggplot(pp_df, aes(x = bmi_c, y = pred)) +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.25) +
geom_line(size = 1.1) +
labs(
title = "Posterior Mean Diabetes Probability vs Standardized BMI",
x = "Standardized BMI (bmi_c)",
y = "Predicted Probability (Posterior Mean)"
)
```

4. Prior vs Posterior Distributions (Key Coefficients)
```{r}
# Posterior coefficient densities
mcmc_areas(
as_draws_df(bayes_fit),
pars = c("b_bmi_c", "b_age_c", "b_sexFemale"),
prob = 0.8
) + ggtitle("Posterior Distributions for Key Coefficients")

# Simple prior overlays for age & BMI assuming Normal(0, 2.5)
set.seed(1)
prior_draws <- tibble(
term   = rep(c("Age (per 1 SD)", "BMI (per 1 SD)"), each = 4000),
value  = c(rnorm(4000, 0, 2.5), rnorm(4000, 0, 2.5)),
source = "Prior"
)

post_draws <- as_draws_df(bayes_fit) %>%
select(b_age_c, b_bmi_c) %>%
tidyr::pivot_longer(everything(), names_to = "term_raw", values_to = "value") %>%
mutate(
term = dplyr::recode(term_raw, b_age_c = "Age (per 1 SD)", b_bmi_c = "BMI (per 1 SD)"),
source = "Posterior"
) %>%
select(term, value, source)

bind_rows(prior_draws, post_draws) %>%
ggplot(aes(x = value, fill = source)) +
geom_density(alpha = 0.4) +
facet_wrap(~ term, scales = "free") +
labs(
title = "Prior vs Posterior (Illustrative) for Age and BMI",
x = "Coefficient",
y = "Density",
fill = ""
)
```

5. Posterior Predictive Checks
```{r}
pp_check(bayes_fit, type = "bars") +
ggtitle("Posterior Predictive Check: Outcome Bars")

pp_check(bayes_fit, type = "stat", stat = "mean") +
ggtitle("Posterior Predictive Check: Mean of Outcome")

pp_check(bayes_fit, type = "scatter_avg") +
ggtitle("Posterior Predictive Check: Scatter (Average)")
```

6. Observed vs Predicted (Calibration-style view)
```{r}
# Posterior expected probabilities for each adult
bayes_pred <- posterior_epred(bayes_fit, newdata = adult, summary = FALSE)

# Robust mean across draws per observation
if (is.matrix(bayes_pred)) {
  # typical shape: draws x N
  pred_prob <- as.numeric(colMeans(bayes_pred, na.rm = TRUE))
} else if (length(dim(bayes_pred)) == 3) {
  # shape: iter x chain x N
  pred_prob <- as.numeric(apply(bayes_pred, 3, mean, na.rm = TRUE))
} else {
  stop("Unexpected shape for posterior_epred() output.")
}

# Add to data frame and plot
adult <- dplyr::mutate(adult, pred_prob = pred_prob)

ggplot(adult, aes(x = pred_prob, y = as.numeric(diabetes_dx))) +
  geom_jitter(height = 0.05, alpha = 0.25) +
  geom_smooth(method = "loess", se = TRUE) +
  labs(
    title = "Observed vs Predicted Probability of Diabetes",
    x = "Predicted Probability (Posterior Mean)",
    y = "Observed Outcome (0/1)"
  ) +
  theme_minimal()
```

7. Posterior vs Population (Survey-weighted) Prevalence
```{r}
# Survey-weighted prevalence (population-representative)
pop_prev <- as.numeric(svymean(~diabetes_dx, nhanes_design_adult, na.rm = TRUE))

# Posterior prevalence from Bayesian model
post_prev <- mean(colMeans(bayes_pred))

bar_df <- tibble(
Source     = c("Survey-weighted (Population)", "Bayesian Posterior"),
Prevalence = c(pop_prev, post_prev)
)

ggplot(bar_df, aes(x = Source, y = Prevalence, fill = Source)) +
geom_col(alpha = 0.85) +
scale_fill_viridis_d(guide = "none") +
labs(
title = "Population vs Posterior Diabetes Prevalence",
y = "Prevalence (Proportion with Diabetes)",
x = NULL
) +
ylim(0, max(bar_df$Prevalence) * 1.15)
```
