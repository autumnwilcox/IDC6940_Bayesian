---
title: "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)"
subtitle: "Capstone Report"
author:
  - "Namita Mishra"
  - "Autumn Wilcox"
  - "Chad Michael Eyer"
  - "Ecil Teodoro"
advisor: "Dr. Ashraf Cohen"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib
self-contained: true
execute:
  warning: false
  message: false
editor:
  markdown:
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} (Edit `slides.qmd`.)

::: callout-important
**Remember:** Keep the story tight: What question, why it matters,
what data, what model, what we found, and what to do with it.
:::

## Introduction

Type 2 diabetes (T2D) is a major public health burden. Early
identification of population-level risk factors—age, BMI category,
sex, and race/ethnicity—supports prevention and targeted intervention.
Classical logistic regression (MLE) can become unstable when effective
sample size shrinks (after missingness handling) or when quasi-/complete
separation occurs. Bayesian logistic regression adds priors that
regularize estimates and provides full uncertainty (posterior) for
transparent decision-making.

**Our question:** Using NHANES 2013–2014, what is the association
between key predictors (BMI category, age, sex, race/ethnicity) and a
diabetes-related outcome, and does a Bayesian approach yield more stable
inference than a frequentist baseline under missingness and potential
separation?

> Note: In this draft we keep the team’s chosen variables unchanged
> (`BMDBMIC`, `DIQ240`, demographics). In the next iteration we may
> swap in `DIQ010` (“ever told you had diabetes”) as a clearer outcome
> and keep `DIQ240` as a predictor.

## Related Work (very brief)

Bayesian methods can stabilize inference with small or messy health
data and quantify uncertainty via posteriors (e.g., hierarchical and
GLM settings). Prior choices and sensitivity checks matter; multiple
imputation can be combined with Bayesian modeling to propagate
uncertainty rather than drop cases. (See full citations in
`references.bib`.)

## Data & Preparation

- **Source:** NHANES (CDC) 2013–2014.
- **Files:** `BMX_H` (body measures), `DEMO_H` (demographics),
  `DIQ_H` (diabetes questionnaire).
- **Variables (kept as your team selected):**
  - Predictors/Covariates: `BMDBMIC` (BMI category), `RIDAGEYR` (age),
    `RIAGENDR` (sex), `RIDRETH1` (race/ethnicity).
  - Survey design: `WTMEC2YR`, `SDMVPSU`, `SDMVSTRA`.
  - Outcome candidate for now: `DIQ240` (usual diabetes doctor; a
    diabetes-related marker, not a diagnosis).

```{r}
# Load packages for this report
library(tidyverse)
library(knitr)

# Build merged dataset if missing (uses R/data_prep.R from the repo)
if (!file.exists("data/merged_2013_2014.rds")) {
  source("R/data_prep.R")
}

# Load merged NHANES data created by R/data_prep.R
merged_data <- readRDS("data/merged_2013_2014.rds")

# Quick peek
knitr::kable(head(merged_data))

```

## Basic Exploration 

```{r}

# Safe tabulations (keep NA visible)
table(merged_data$BMDBMIC, useNA = "ifany")
table(merged_data$DIQ240,  useNA = "ifany")

# Age distribution
ggplot(merged_data, aes(x = RIDAGEYR)) +
  geom_histogram(binwidth = 5, boundary = 0, closed = "left") +
  labs(title = "Age distribution (NHANES 2013–2014)",
       x = "Age (years)", y = "Count") +
  theme_minimal()

# BMI category counts (codes as-is)
merged_data %>%
  mutate(BMDBMIC = factor(BMDBMIC, exclude = NULL)) %>%
  count(BMDBMIC) %>%
  ggplot(aes(x = BMDBMIC, y = n)) +
  geom_col() +
  labs(title = "Counts by BMDBMIC (BMI category code)",
       x = "BMDBMIC (code; NA common for adults)", y = "Count") +
  theme_minimal()

```

## Survey Design

``` {r}

# Survey design setup (weights/strata/PSU)
library(survey)
nhanes_design <- svydesign(
  id = ~SDMVPSU,
  strata = ~SDMVSTRA,
  weights = ~WTMEC2YR,
  nest = TRUE,
  data = merged_data
)

# Example: weighted mean age
svymean(~RIDAGEYR, nhanes_design, na.rm = TRUE)

```

## Methods

- **Baseline:** Frequentist logistic regression (MLE).
- **Main:** Bayesian logistic regression with weakly-informative priors
for stability and honest uncertainty intervals.
- **Missingness:** Prefer multiple imputation (or Bayesian models with
missing data mechanisms) over listwise deletion to retain ~9,800
observations and avoid separation artifacts. We will run prior
sensitivity checks.

## Modeling (placeholders)

```{r}

# Example skeletons (commented until outcome is finalized)

# library(rstanarm)  # or library(brms)

# Frequentist baseline:
# fit_mle <- glm(outcome ~ BMDBMIC + RIDAGEYR + RIAGENDR + RIDRETH1 + DIQ240,
#                data = merged_data, family = binomial())

# Bayesian (weakly-informative priors):
# fit_bayes <- rstanarm::stan_glm(
#   outcome ~ BMDBMIC + RIDAGEYR + RIAGENDR + RIDRETH1 + DIQ240,
#   data = merged_data, family = binomial(),
#   prior = rstanarm::normal(0, 2.5),
#   prior_intercept = rstanarm::normal(0, 5),
#   chains = 4, iter = 2000, seed = 123
# )

# Next steps:
# - finalize outcome (prefer DIQ010), run MI if needed, then fit both models
# - compare odds ratios/posteriors, AUC, calibration, and survey-weighted variants

```

## Results (to be populated)

- Posterior summaries and credible intervals for effects.
- Predictive performance vs. MLE baseline.
- Sensitivity to priors; effect of handling missingness vs. deletion.

## Discussion & Conclusion

- Bayesian logistic regression is a good fit for survey data with
missingness and potential separation, providing stable estimates and
interpretable uncertainty.
- Next: finalize the outcome (DIQ010), run MI, fit survey-aware models,
and present results with clear figures and tables.

## References

```{r}

# Optional reproducibility details
sessionInfo()

```
