---
title: "Bayesian Logistic Regression for Predicting Diabetes Risk"
subtitle: "NHANES 2013–2014 Analysis"
author: |
  **Namita Mishra**  
  **Autumn Wilcox**
institute: "University of West Florida — M.S. Data Science"
date: "December 2025"
format:
  revealjs:
    theme: simple
    transition: fade
    slide-number: true
    toc: false
    incremental: true
    scrollable: true
    footer: "Capstone Project · UWF Data Science Program"
execute:
  echo: false
  warning: false
  message: false
bibliography: references.bib
editor: visual
---

## Introduction

- **Diabetes mellitus (DM)** is a major U.S. public health challenge, affecting over 37 million adults.  
- Identifying key risk factors — **age, body mass index (BMI), sex, and race/ethnicity** — supports targeted prevention and early intervention.  
- Traditional **logistic regression** can yield unstable estimates with missing data or small subgroup sizes.  
- **Bayesian logistic regression** integrates prior information and quantifies uncertainty more transparently.  
- This project compares three analytic frameworks using NHANES 2013–2014 data:
  - Survey-weighted logistic regression  
  - Multiple imputation (MICE)  
  - Bayesian logistic regression with weakly informative priors  

---

## Methods — Study Design & Data Preparation

- **Dataset:** NHANES 2013–2014  
  - n = 5,769 adults aged ≥20 years  
  - Variables: age, BMI, sex, race/ethnicity, and doctor-diagnosed diabetes  

- **Survey Design:**  
  - Complex, multistage sampling with strata, clusters, and sample weights  
  - Weights normalized and treated as importance weights in modeling  

- **Data Preparation:**  
  - Missing data handled using *Multiple Imputation by Chained Equations (MICE)*  
  - Continuous predictors (age, BMI) standardized as z-scores  
  - Demographic variables recoded into analysis categories  

---

## Methods — Modeling Framework

- **Models Compared**
  1. Survey-weighted logistic regression (design-based MLE)  
  2. MICE-imputed logistic regression (Rubin’s rules for pooling)  
  3. Bayesian logistic regression using *brms* (Hamiltonian Monte Carlo)  

- **Bayesian Priors**
  - Slopes: \( \mathcal{N}(0, 2.5) \)  
  - Intercept: Student-t(3, 0, 10)  

- **Diagnostics**
  - Convergence: \( \hat{R} \approx 1.00 \); ESS > 2,000  
  - Posterior predictive checks (PPC) for calibration  
  - Bayesian \( R^2 \approx 0.13 \) for model fit  

---

::: notes
**Presenter Notes:**
- On the introduction slide: Emphasize that the study compares three modeling approaches on the same predictors for consistency.  
- On “Study Design & Data Preparation”: Explain that NHANES is nationally representative and imputation mitigated bias from incomplete records (~7% missingness).  
- On “Modeling Framework”: Highlight how Bayesian inference adds credible intervals, uncertainty quantification, and PPC diagnostics beyond traditional methods.  
:::

---

## Results — Model Comparison

- All three modeling frameworks identified **consistent predictors** of diabetes risk:  
  - **Higher age** and **BMI** substantially increased odds of diabetes.  
  - **Females** had lower odds compared to males.  
  - **Non-White racial/ethnic groups** showed higher odds relative to Non-Hispanic Whites.  

- **Estimated odds ratios (per 1 SD increase):**
  - Age: ~3.0  
  - BMI: ~1.8–1.9  
  - Female: 0.52 (protective)  

- **Agreement across frameworks:**
  - Bayesian, survey-weighted, and imputed logistic regressions produced nearly identical effect directions and magnitudes.  
  - Minor variation in interval widths reflects different treatments of uncertainty.  

---

## Results — Bayesian Model Performance

- **Priors:** Weakly informative — \( \mathcal{N}(0, 2.5) \) for slopes, Student-t(3, 0, 10) for intercept.  
- **MCMC diagnostics:**  
  - \( \hat{R} \approx 1.00 \), ESS > 2,000 → excellent convergence  
  - Trace plots showed stable, overlapping chains  
  - Posterior distributions unimodal and well-centered  

- **Model fit:**
  - Bayesian \( R^2 = 0.13 \), consistent with moderate explanatory power for demographic data  
  - Posterior predictive checks showed good calibration between observed and replicated outcomes  

- **Interpretation:**  
  - Bayesian credible intervals provided clearer uncertainty quantification.  
  - The model generalized the classical results while improving interpretability and transparency.  

---

::: notes
**Presenter Notes:**
- On the first results slide: Emphasize how the consistency across all three frameworks increases confidence in the findings.  
- Mention that odds ratios close across models indicate robustness to missing data and modeling approach.  
- On the second slide: Point out that diagnostics confirmed strong model behavior — no convergence issues, well-behaved chains, and realistic fit.  
- Highlight that Bayesian inference adds probabilistic interpretability (credible intervals, posterior predictive checks).
:::

---

## Discussion

- **Interpretation**
  - Bayesian, survey-weighted, and imputed logistic regression models yielded nearly identical effect directions and magnitudes.  
  - Age and BMI were the strongest predictors of diabetes, with each 1 SD increase in age nearly tripling the odds of diagnosis.  
  - Females showed lower odds than males, and non-White racial and ethnic groups had higher odds relative to Non-Hispanic Whites.  

- **Implications**
  - Consistency across models reinforces the robustness of these predictors.  
  - Bayesian inference improves interpretability through credible intervals and posterior distributions.  
  - Posterior predictive checks confirm that the Bayesian model accurately reproduces observed data patterns.  

---

## Limitations & Conclusion

- **Limitations**
  - Single imputed dataset used for Bayesian modeling may understate total variance.  
  - Normalized NHANES weights approximate but do not fully reproduce design-based inference.  
  - Weakly informative priors were not empirically tuned; alternate priors could slightly shift posterior intervals.  
  - Results are conditional on the 2013–2014 NHANES cycle and not yet externally validated.  

- **Conclusion**
  - Bayesian logistic regression produced results consistent with frequentist frameworks while offering richer uncertainty quantification.  
  - Diagnostics confirmed excellent convergence (R̂ ≈ 1.00, ESS > 2,000, Bayesian R² ≈ 0.13).  
  - Bayesian inference enhances model transparency and interpretability for population health research.  
  - Future work: integrate hierarchical priors, combine multiple NHANES cycles, and conduct sensitivity analyses for external validation.  

---

::: notes
**Presenter Notes:**
- Discussion slide: Highlight the consistency across models and the interpretive value of Bayesian inference for uncertainty communication.  
- Limitations slide: Be brief — you can mention the single-imputation choice and note that results generalize only to 2013–2014 adults.  
- Conclusion: End confidently — emphasize that Bayesian methods complement, not replace, classical approaches by enhancing inference and transparency.  
:::

---

## Key Takeaways

- **Consistency Across Methods**  
  Bayesian, survey-weighted, and imputed logistic regressions all identified the same core risk factors for diabetes — higher **age**, higher **BMI**, and **non-White race/ethnicity**.

- **Bayesian Value Add**  
  Provides full posterior distributions, credible intervals, and model diagnostics — offering deeper insight into **uncertainty and fit**.

- **Model Performance**  
  Strong convergence (R̂ ≈ 1.00, ESS > 2,000) and good calibration in posterior predictive checks confirm model reliability.

- **Future Directions**  
  Expand to multiple NHANES cycles, test hierarchical priors, and validate results in external datasets.

---

::: notes
**Presenter Notes:**
- Keep this slide visible during Q&A.  
- Reinforce that Bayesian methods complement frequentist tools rather than replacing them.  
- Emphasize that this framework improves transparency and reproducibility — two goals central to modern data science and public health modeling.
:::

---

## Acknowledgments & Q&A

**Team Members**  
- Namita Mishra  
- Autumn Wilcox  

**Advisor**  
- Dr. Ashraf Cohen, University of West Florida  

---

### Thank you!

**Questions?**  

*Capstone Project — M.S. Data Science, University of West Florida*  
