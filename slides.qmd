---
title: "Bayesian Logistic Regression for Diabetes Risk (NHANES 2013–2014)"
subtitle: "Capstone Presentation — Bayesian Modeling of NHANES 2013–2014 Data"

author:
  - name: "Namita Mishra"
    affiliation: "University of West Florida"
  - name: "Autumn Wilcox"
    affiliation: "University of West Florida"

advisor: "Advisor: Dr. Ashraf Cohen"

format:
  revealjs:
    theme: simple
    slide-number: true
    transition: slide
    css: docs/slides.css
    incremental: true
    code-fold: true
    code-summary: "Show Code"
    highlight-style: github
    code-overflow: wrap
    auto-stretch: true

bibliography: references.bib

execute:
  warning: false
  message: false
  echo: false
---

## Aim

-   **Early identification** of key risk factors is essential for diabetes prevention.\
-   Use **Bayesian logistic regression** to model and predict diabetes risk\
    based on **NHANES 2013–2014** data.

------------------------------------------------------------------------

## Frequentist Methods

-   Based on **Maximum Likelihood Estimation (MLE)**.\
-   Can become unstable with **missing data**, **small samples**, or **quasi-separation**.\
-   Interprets probability as a **long-run relative frequency** —\
    the proportion of times an event would occur over infinite repetitions.

------------------------------------------------------------------------

## Bayesian Approach

-   Offers **flexibility** and **regularization** for more stable estimation.\
-   Quantifies **uncertainty** under missingness and imputation\
    [@baldwin2017; @kruschke2017].\
-   Incorporates **priors** and produces **credible intervals** via MCMC sampling.\
-   Enables **model checking**, **variable selection**, and **uncertainty quantification**.\
-   Defines probability as a **degree of belief**, not long-run frequency.

------------------------------------------------------------------------

## Bayesian Model

::: panel-tabset
### Bayes’ Theorem

-   **Bayes’ theorem** updates prior beliefs with observed data to obtain posterior probabilities.\
-   Model coefficients are estimated using **posterior means** and **95% credible intervals**.\
-   A **logistic link function** is used for the binary diabetes outcome.

### Bayesian Logistic Regression

$$
\text{logit}\big(P(Y = 1)\big) =
\beta_0 +
\beta_1(\text{age}_c) +
\beta_2(\text{bmi}_c) +
\beta_3(\text{sex}) +
\beta_4(\text{race})
$$

-   **Intercept prior:** Student’s *t*(3, 0, 10) — heavy tails allow occasional large effects [@vandeschoot2013].\
-   **Regression coefficients prior:** Normal(0, 2.5) — weakly informative, constraining extreme values [@vandeschoot2021].
:::

------------------------------------------------------------------------

## Bayesian Logistic Regression (in R)

-   Implemented using **`brms`** (with **Stan** as the MCMC backend).\
-   **4 chains × 2000 iterations**, with **1000 warmup** → **4000 posterior draws**.\
-   **Survey weights** included via `weights(wt_norm)` to reflect NHANES design.

``` r
library(brms)

priors <- c(
  set_prior("normal(0, 2.5)", class = "b"),
  set_prior("student_t(3, 0, 10)", class = "Intercept")
)

bayes_fit <- brm(
  formula = diabetes_dx | weights(wt_norm) ~ age_c + bmi_c + sex + race,
  data    = adult_imp1,
  family  = bernoulli(link = "logit"),
  prior   = priors,
  chains  = 4, iter = 2000, seed = 123,
  control = list(adapt_delta = 0.95),
  refresh = 0
)
```

------------------------------------------------------------------------

## Data Source

### NHANES 2013–2014 (Survey Weighted)

:::::: panel-tabset
### Exploratory Data Analysis

-   **Response variable:** `diabetes_dx` (binary) — Type 2 diagnosis (`DIQ010`: “Doctor told you have diabetes”).\
    *Excluded* `DIQ050` (insulin use) to avoid confounding.

-   **Predictors:**

    -   `BMXBMI` — Body Mass Index (kg/m²), continuous and categorized (`bmi_cat`)\
    -   `RIDAGEYR` — Age (continuous, 20–80 yrs)\
    -   `RIAGENDR` — Sex (Male / Female)\
    -   `RIDRETH1` — Ethnicity (5 levels → 4 analytic groups)

### Missing Data Analysis

::::: columns
::: column
**Missingness Plot**\
<!-- Add your actual image path below --> <!-- ![](images/clipboard-2873800077.png){width="427"} -->
:::

::: column
-   Overall missingness ≈ **4%**\
-   Missingness concentrated in **BMI (4.3%)** and **diabetes_dx (3.1%)**\
-   No variable completely missing\
-   Likely **MAR** (Missing At Random) pattern\
:::
:::::
::::::

------------------------------------------------------------------------

## Handling Missing Data

### Multiple Imputation by Chained Equations (MICE)

[@vanbuuren2011; @vanbuuren2012]

-   Iteratively imputes incomplete variables using **regression models**.\
-   Uses **Predictive Mean Matching (PMM)** for continuous variables and\
    **logistic/polytomous regression** for categorical variables.\
-   Conducted **5 imputations × 10 iterations** to ensure stability and convergence.\
-   Pooled results combined using **Rubin’s rules** to account for imputation uncertainty.

``` r
fit_mi <- with(
  data = imp,
  exp = glm(diabetes_dx ~ age_c + bmi_c + sex + race, family = binomial())
)
pool_mi <- pool(fit_mi)
```

------------------------------------------------------------------------

## Bayesian Model Diagnostics

::: panel-tabset
### MCMC Convergence

-   **Trace plots** show stable mixing across all chains.\
-   **R̂ ≈ 1.00** → convergence achieved.\
-   **Effective sample sizes** are adequate for all parameters, indicating reliable sampling.

### Posterior Estimates

-   **Intercept:** −2.66 \[−2.84, −2.50\] → baseline log-odds.\
-   **Age_c:** 1.09 \[0.97, 1.22\] → higher age increases diabetes risk.\
-   **BMI_c:** 0.88 \[0.76, 1.01\] → higher BMI predicts greater diabetes risk.\
-   All predictors positive and precise (**narrow credible intervals**, none include 0).
:::

------------------------------------------------------------------------

## Posterior Predictive Distribution

::: panel-tabset
### Code

``` r
library(ggplot2)

ggplot(combined_draws, aes(x = estimate, fill = type)) +
  geom_density(alpha = 0.4) +
  facet_wrap(~ term, scales = "free", ncol = 2) +
  theme_minimal(base_size = 13) +
  labs(
    title = "Prior vs Posterior Distributions",
    x = "Coefficient Estimate",
    y = "Density",
    fill = ""
  )
```

------------------------------------------------------------------------

### Interpretation

-   Strong positive relationship between **age**, **BMI**, and diabetes probability.
-   **Posterior predictive checks** confirm good model fit.\
-   Imputation reduced bias and improved robustness.\
-   **Bayesian R² ≈ 0.13** → model explains \~13% of outcome variance.

``` text
        Estimate    Est.Error     Q2.5     Q97.5 
        R2 0.1313   0.0127       0.1065   0.1561
```
:::

------------------------------------------------------------------------

## Assumptions for Bayesian Logistic Regression

::: nonincremental
-   **Data:** Binary outcome variable.\
-   **Observations:** Independent across participants.\
-   **Relationship:** Linear in the logit.\
-   **Multicollinearity:** None among predictors.\
-   **Priors:** Properly chosen and sufficiently informative for stabilization.\
-   **Posterior:** Proper, well-converged fit.\
-   **Separation:** No complete separation in the data.\
-   **Model Checks:** Satisfactory posterior predictive performance.\
:::

------------------------------------------------------------------------

## Limitations

::: nonincremental
-   NHANES is **cross-sectional**, limiting causal inference.\
-   Possible **unmeasured confounders** (e.g., diet, activity level).\
-   Simplified model with a **restricted set of predictors**.\
-   Imputation assumes **MAR**; violations may introduce bias.\
:::

------------------------------------------------------------------------

## Conclusion

-   **Bayesian logistic regression** effectively captures parameter uncertainty.\
-   **MICE** improved data completeness and reliability.\
-   Posterior predictions yield **interpretable estimates of diabetes risk**.\
-   The framework can extend to other outcomes (e.g., hypertension, obesity).

------------------------------------------------------------------------

## References

------------------------------------------------------------------------

## Acknowledgements

**Dr. Ashraf Cohen, PhD, MS**\
University of West Florida\
Department of Mathematics & Statistics

We sincerely thank you for your continued guidance and support throughout this project.

------------------------------------------------------------------------
